{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set the current working directory\n",
    "curr_path = os.getcwd().split(\"/\")[:-1]\n",
    "curr_path = \"/\".join(curr_path)\n",
    "os.chdir(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No coordinates found.\n",
      "Generating coordinates using spring layout.\n",
      "Num. of nodes: 25\n",
      "Num. of edges: 210\n",
      "Num. of triangles: 770\n",
      "Shape: (25, 210, 770)\n",
      "Max Dimension: 2\n",
      "Coordinates: 25\n",
      "Flow: 210\n",
      "Flow: 210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# read dataset\n",
    "from pytspl import load_dataset\n",
    "\n",
    "sc, _, flow = load_dataset(\"forex\")\n",
    "# get the y from flow dict\n",
    "y = np.fromiter(flow.values(), dtype=float)\n",
    "\n",
    "print(\"Flow:\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytspl.hogde_gp import HodgeGPTrainer\n",
    "\n",
    "# create the trainer object\n",
    "hogde_gp = HodgeGPTrainer(sc = sc, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (42,)\n",
      "x_test: (168,)\n",
      "y_train: (42,)\n",
      "y_test: (168,)\n"
     ]
    }
   ],
   "source": [
    "# set the parameters\n",
    "\n",
    "# set the training ratio\n",
    "train_ratio = 0.2\n",
    "# set the data normalization\n",
    "data_normalization = False\n",
    "\n",
    "# get the eigenpairs\n",
    "eigenpairs = hogde_gp.get_eigenpairs()\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, y_train, x_test, y_test, x, y  = hogde_gp.train_test_split(train_ratio=train_ratio, data_normalization=data_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(34.), tensor(4.4740))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytspl.hogde_gp.kernel_serializer import KernelSerializer\n",
    "\n",
    "# set the kernel parameters\n",
    "\n",
    "kernel_type = \"matern\" # kernel type\n",
    "data_name = \"forex\" # data set name\n",
    "\n",
    "# serialize the kernel\n",
    "kernel = KernelSerializer().serialize(eigenpairs=eigenpairs, kernel_type=kernel_type, data_name=data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from pytspl.hogde_gp import ExactGPModel\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train, y_train, likelihood, kernel, mean_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytspl.hogde_gp.forex.matern.MaternKernelForex"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "output_device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   model = model.to(output_device)\n",
    "   likelihood = likelihood.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: likelihood.noise_covar.raw_noise                   value = 0.0\n",
      "Parameter name: mean_module.raw_constant                           value = 0.0\n",
      "Parameter name: covar_module.raw_outputscale                       value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_kappa_down            value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_kappa_up              value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_kappa                 value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_mu                    value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_mu_down               value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_mu_up                 value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_h                     value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_h_down                value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_h_up                  value = 0.0\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:50} value = {param.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1000 - Loss: 3.867 \n",
      "Iteration 2/1000 - Loss: 3.571 \n",
      "Iteration 3/1000 - Loss: 3.321 \n",
      "Iteration 4/1000 - Loss: 3.112 \n",
      "Iteration 5/1000 - Loss: 2.939 \n",
      "Iteration 6/1000 - Loss: 2.795 \n",
      "Iteration 7/1000 - Loss: 2.676 \n",
      "Iteration 8/1000 - Loss: 2.577 \n",
      "Iteration 9/1000 - Loss: 2.495 \n",
      "Iteration 10/1000 - Loss: 2.426 \n",
      "Iteration 11/1000 - Loss: 2.369 \n",
      "Iteration 12/1000 - Loss: 2.322 \n",
      "Iteration 13/1000 - Loss: 2.283 \n",
      "Iteration 14/1000 - Loss: 2.251 \n",
      "Iteration 15/1000 - Loss: 2.226 \n",
      "Iteration 16/1000 - Loss: 2.206 \n",
      "Iteration 17/1000 - Loss: 2.190 \n",
      "Iteration 18/1000 - Loss: 2.179 \n",
      "Iteration 19/1000 - Loss: 2.170 \n",
      "Iteration 20/1000 - Loss: 2.164 \n",
      "Iteration 21/1000 - Loss: 2.160 \n",
      "Iteration 22/1000 - Loss: 2.157 \n",
      "Iteration 23/1000 - Loss: 2.156 \n",
      "Iteration 24/1000 - Loss: 2.155 \n",
      "Iteration 25/1000 - Loss: 2.155 \n",
      "Iteration 26/1000 - Loss: 2.155 \n",
      "Iteration 27/1000 - Loss: 2.155 \n",
      "Iteration 28/1000 - Loss: 2.155 \n",
      "Iteration 29/1000 - Loss: 2.155 \n",
      "Iteration 30/1000 - Loss: 2.155 \n",
      "Iteration 31/1000 - Loss: 2.154 \n",
      "Iteration 32/1000 - Loss: 2.153 \n",
      "Iteration 33/1000 - Loss: 2.152 \n",
      "Iteration 34/1000 - Loss: 2.151 \n",
      "Iteration 35/1000 - Loss: 2.149 \n",
      "Iteration 36/1000 - Loss: 2.147 \n",
      "Iteration 37/1000 - Loss: 2.145 \n",
      "Iteration 38/1000 - Loss: 2.142 \n",
      "Iteration 39/1000 - Loss: 2.140 \n",
      "Iteration 40/1000 - Loss: 2.137 \n",
      "Iteration 41/1000 - Loss: 2.134 \n",
      "Iteration 42/1000 - Loss: 2.130 \n",
      "Iteration 43/1000 - Loss: 2.127 \n",
      "Iteration 44/1000 - Loss: 2.124 \n",
      "Iteration 45/1000 - Loss: 2.120 \n",
      "Iteration 46/1000 - Loss: 2.117 \n",
      "Iteration 47/1000 - Loss: 2.113 \n",
      "Iteration 48/1000 - Loss: 2.110 \n",
      "Iteration 49/1000 - Loss: 2.106 \n",
      "Iteration 50/1000 - Loss: 2.103 \n",
      "Iteration 51/1000 - Loss: 2.100 \n",
      "Iteration 52/1000 - Loss: 2.096 \n",
      "Iteration 53/1000 - Loss: 2.093 \n",
      "Iteration 54/1000 - Loss: 2.090 \n",
      "Iteration 55/1000 - Loss: 2.086 \n",
      "Iteration 56/1000 - Loss: 2.083 \n",
      "Iteration 57/1000 - Loss: 2.080 \n",
      "Iteration 58/1000 - Loss: 2.077 \n",
      "Iteration 59/1000 - Loss: 2.073 \n",
      "Iteration 60/1000 - Loss: 2.070 \n",
      "Iteration 61/1000 - Loss: 2.067 \n",
      "Iteration 62/1000 - Loss: 2.064 \n",
      "Iteration 63/1000 - Loss: 2.060 \n",
      "Iteration 64/1000 - Loss: 2.057 \n",
      "Iteration 65/1000 - Loss: 2.054 \n",
      "Iteration 66/1000 - Loss: 2.050 \n",
      "Iteration 67/1000 - Loss: 2.047 \n",
      "Iteration 68/1000 - Loss: 2.043 \n",
      "Iteration 69/1000 - Loss: 2.040 \n",
      "Iteration 70/1000 - Loss: 2.036 \n",
      "Iteration 71/1000 - Loss: 2.032 \n",
      "Iteration 72/1000 - Loss: 2.029 \n",
      "Iteration 73/1000 - Loss: 2.025 \n",
      "Iteration 74/1000 - Loss: 2.021 \n",
      "Iteration 75/1000 - Loss: 2.017 \n",
      "Iteration 76/1000 - Loss: 2.013 \n",
      "Iteration 77/1000 - Loss: 2.009 \n",
      "Iteration 78/1000 - Loss: 2.005 \n",
      "Iteration 79/1000 - Loss: 2.001 \n",
      "Iteration 80/1000 - Loss: 1.997 \n",
      "Iteration 81/1000 - Loss: 1.993 \n",
      "Iteration 82/1000 - Loss: 1.989 \n",
      "Iteration 83/1000 - Loss: 1.984 \n",
      "Iteration 84/1000 - Loss: 1.980 \n",
      "Iteration 85/1000 - Loss: 1.976 \n",
      "Iteration 86/1000 - Loss: 1.972 \n",
      "Iteration 87/1000 - Loss: 1.968 \n",
      "Iteration 88/1000 - Loss: 1.963 \n",
      "Iteration 89/1000 - Loss: 1.959 \n",
      "Iteration 90/1000 - Loss: 1.955 \n",
      "Iteration 91/1000 - Loss: 1.951 \n",
      "Iteration 92/1000 - Loss: 1.947 \n",
      "Iteration 93/1000 - Loss: 1.942 \n",
      "Iteration 94/1000 - Loss: 1.938 \n",
      "Iteration 95/1000 - Loss: 1.934 \n",
      "Iteration 96/1000 - Loss: 1.930 \n",
      "Iteration 97/1000 - Loss: 1.926 \n",
      "Iteration 98/1000 - Loss: 1.922 \n",
      "Iteration 99/1000 - Loss: 1.917 \n",
      "Iteration 100/1000 - Loss: 1.913 \n",
      "Iteration 101/1000 - Loss: 1.909 \n",
      "Iteration 102/1000 - Loss: 1.905 \n",
      "Iteration 103/1000 - Loss: 1.901 \n",
      "Iteration 104/1000 - Loss: 1.897 \n",
      "Iteration 105/1000 - Loss: 1.893 \n",
      "Iteration 106/1000 - Loss: 1.889 \n",
      "Iteration 107/1000 - Loss: 1.884 \n",
      "Iteration 108/1000 - Loss: 1.880 \n",
      "Iteration 109/1000 - Loss: 1.876 \n",
      "Iteration 110/1000 - Loss: 1.872 \n",
      "Iteration 111/1000 - Loss: 1.868 \n",
      "Iteration 112/1000 - Loss: 1.863 \n",
      "Iteration 113/1000 - Loss: 1.859 \n",
      "Iteration 114/1000 - Loss: 1.855 \n",
      "Iteration 115/1000 - Loss: 1.850 \n",
      "Iteration 116/1000 - Loss: 1.846 \n",
      "Iteration 117/1000 - Loss: 1.841 \n",
      "Iteration 118/1000 - Loss: 1.837 \n",
      "Iteration 119/1000 - Loss: 1.832 \n",
      "Iteration 120/1000 - Loss: 1.827 \n",
      "Iteration 121/1000 - Loss: 1.822 \n",
      "Iteration 122/1000 - Loss: 1.818 \n",
      "Iteration 123/1000 - Loss: 1.812 \n",
      "Iteration 124/1000 - Loss: 1.807 \n",
      "Iteration 125/1000 - Loss: 1.802 \n",
      "Iteration 126/1000 - Loss: 1.797 \n",
      "Iteration 127/1000 - Loss: 1.791 \n",
      "Iteration 128/1000 - Loss: 1.786 \n",
      "Iteration 129/1000 - Loss: 1.780 \n",
      "Iteration 130/1000 - Loss: 1.774 \n",
      "Iteration 131/1000 - Loss: 1.768 \n",
      "Iteration 132/1000 - Loss: 1.761 \n",
      "Iteration 133/1000 - Loss: 1.755 \n",
      "Iteration 134/1000 - Loss: 1.749 \n",
      "Iteration 135/1000 - Loss: 1.742 \n",
      "Iteration 136/1000 - Loss: 1.735 \n",
      "Iteration 137/1000 - Loss: 1.728 \n",
      "Iteration 138/1000 - Loss: 1.720 \n",
      "Iteration 139/1000 - Loss: 1.713 \n",
      "Iteration 140/1000 - Loss: 1.705 \n",
      "Iteration 141/1000 - Loss: 1.697 \n",
      "Iteration 142/1000 - Loss: 1.689 \n",
      "Iteration 143/1000 - Loss: 1.680 \n",
      "Iteration 144/1000 - Loss: 1.672 \n",
      "Iteration 145/1000 - Loss: 1.663 \n",
      "Iteration 146/1000 - Loss: 1.653 \n",
      "Iteration 147/1000 - Loss: 1.644 \n",
      "Iteration 148/1000 - Loss: 1.634 \n",
      "Iteration 149/1000 - Loss: 1.624 \n",
      "Iteration 150/1000 - Loss: 1.614 \n",
      "Iteration 151/1000 - Loss: 1.603 \n",
      "Iteration 152/1000 - Loss: 1.592 \n",
      "Iteration 153/1000 - Loss: 1.581 \n",
      "Iteration 154/1000 - Loss: 1.570 \n",
      "Iteration 155/1000 - Loss: 1.558 \n",
      "Iteration 156/1000 - Loss: 1.546 \n",
      "Iteration 157/1000 - Loss: 1.533 \n",
      "Iteration 158/1000 - Loss: 1.521 \n",
      "Iteration 159/1000 - Loss: 1.507 \n",
      "Iteration 160/1000 - Loss: 1.494 \n",
      "Iteration 161/1000 - Loss: 1.480 \n",
      "Iteration 162/1000 - Loss: 1.466 \n",
      "Iteration 163/1000 - Loss: 1.452 \n",
      "Iteration 164/1000 - Loss: 1.437 \n",
      "Iteration 165/1000 - Loss: 1.422 \n",
      "Iteration 166/1000 - Loss: 1.407 \n",
      "Iteration 167/1000 - Loss: 1.392 \n",
      "Iteration 168/1000 - Loss: 1.376 \n",
      "Iteration 169/1000 - Loss: 1.360 \n",
      "Iteration 170/1000 - Loss: 1.343 \n",
      "Iteration 171/1000 - Loss: 1.326 \n",
      "Iteration 172/1000 - Loss: 1.309 \n",
      "Iteration 173/1000 - Loss: 1.292 \n",
      "Iteration 174/1000 - Loss: 1.274 \n",
      "Iteration 175/1000 - Loss: 1.257 \n",
      "Iteration 176/1000 - Loss: 1.239 \n",
      "Iteration 177/1000 - Loss: 1.220 \n",
      "Iteration 178/1000 - Loss: 1.202 \n",
      "Iteration 179/1000 - Loss: 1.183 \n",
      "Iteration 180/1000 - Loss: 1.164 \n",
      "Iteration 181/1000 - Loss: 1.145 \n",
      "Iteration 182/1000 - Loss: 1.126 \n",
      "Iteration 183/1000 - Loss: 1.107 \n",
      "Iteration 184/1000 - Loss: 1.087 \n",
      "Iteration 185/1000 - Loss: 1.067 \n",
      "Iteration 186/1000 - Loss: 1.048 \n",
      "Iteration 187/1000 - Loss: 1.028 \n",
      "Iteration 188/1000 - Loss: 1.008 \n",
      "Iteration 189/1000 - Loss: 0.988 \n",
      "Iteration 190/1000 - Loss: 0.968 \n",
      "Iteration 191/1000 - Loss: 0.947 \n",
      "Iteration 192/1000 - Loss: 0.927 \n",
      "Iteration 193/1000 - Loss: 0.907 \n",
      "Iteration 194/1000 - Loss: 0.886 \n",
      "Iteration 195/1000 - Loss: 0.866 \n",
      "Iteration 196/1000 - Loss: 0.845 \n",
      "Iteration 197/1000 - Loss: 0.824 \n",
      "Iteration 198/1000 - Loss: 0.804 \n",
      "Iteration 199/1000 - Loss: 0.783 \n",
      "Iteration 200/1000 - Loss: 0.762 \n",
      "Iteration 201/1000 - Loss: 0.741 \n",
      "Iteration 202/1000 - Loss: 0.721 \n",
      "Iteration 203/1000 - Loss: 0.700 \n",
      "Iteration 204/1000 - Loss: 0.679 \n",
      "Iteration 205/1000 - Loss: 0.658 \n",
      "Iteration 206/1000 - Loss: 0.637 \n",
      "Iteration 207/1000 - Loss: 0.616 \n",
      "Iteration 208/1000 - Loss: 0.596 \n",
      "Iteration 209/1000 - Loss: 0.575 \n",
      "Iteration 210/1000 - Loss: 0.554 \n",
      "Iteration 211/1000 - Loss: 0.534 \n",
      "Iteration 212/1000 - Loss: 0.516 \n",
      "Iteration 213/1000 - Loss: 0.551 \n",
      "Iteration 214/1000 - Loss: 0.583 \n",
      "Iteration 215/1000 - Loss: 0.455 \n",
      "Iteration 216/1000 - Loss: 0.543 \n",
      "Iteration 217/1000 - Loss: 0.417 \n",
      "Iteration 218/1000 - Loss: 0.500 \n",
      "Iteration 219/1000 - Loss: 0.385 \n",
      "Iteration 220/1000 - Loss: 0.453 \n",
      "Iteration 221/1000 - Loss: 0.355 \n",
      "Iteration 222/1000 - Loss: 0.405 \n",
      "Iteration 223/1000 - Loss: 0.324 \n",
      "Iteration 224/1000 - Loss: 0.361 \n",
      "Iteration 225/1000 - Loss: 0.290 \n",
      "Iteration 226/1000 - Loss: 0.325 \n",
      "Iteration 227/1000 - Loss: 0.252 \n",
      "Iteration 228/1000 - Loss: 0.294 \n",
      "Iteration 229/1000 - Loss: 0.216 \n",
      "Iteration 230/1000 - Loss: 0.260 \n",
      "Iteration 231/1000 - Loss: 0.191 \n",
      "Iteration 232/1000 - Loss: 0.209 \n",
      "Iteration 233/1000 - Loss: 0.188 \n",
      "Iteration 234/1000 - Loss: 0.145 \n",
      "Iteration 235/1000 - Loss: 0.177 \n",
      "Iteration 236/1000 - Loss: 0.125 \n",
      "Iteration 237/1000 - Loss: 0.109 \n",
      "Iteration 238/1000 - Loss: 0.133 \n",
      "Iteration 239/1000 - Loss: 0.092 \n",
      "Iteration 240/1000 - Loss: 0.058 \n",
      "Iteration 241/1000 - Loss: 0.079 \n",
      "Iteration 242/1000 - Loss: 0.087 \n",
      "Iteration 243/1000 - Loss: 0.048 \n",
      "Iteration 244/1000 - Loss: 0.009 \n",
      "Iteration 245/1000 - Loss: 0.008 \n",
      "Iteration 246/1000 - Loss: 0.034 \n",
      "Iteration 247/1000 - Loss: 0.067 \n",
      "Iteration 248/1000 - Loss: 0.062 \n",
      "Iteration 249/1000 - Loss: -0.002 \n",
      "Iteration 250/1000 - Loss: -0.054 \n",
      "Iteration 251/1000 - Loss: -0.040 \n",
      "Iteration 252/1000 - Loss: 0.009 \n",
      "Iteration 253/1000 - Loss: 0.029 \n",
      "Iteration 254/1000 - Loss: -0.025 \n",
      "Iteration 255/1000 - Loss: -0.090 \n",
      "Iteration 256/1000 - Loss: -0.084 \n",
      "Iteration 257/1000 - Loss: -0.034 \n",
      "Iteration 258/1000 - Loss: -0.020 \n",
      "Iteration 259/1000 - Loss: -0.072 \n",
      "Iteration 260/1000 - Loss: -0.125 \n",
      "Iteration 261/1000 - Loss: -0.114 \n",
      "Iteration 262/1000 - Loss: -0.072 \n",
      "Iteration 263/1000 - Loss: -0.062 \n",
      "Iteration 264/1000 - Loss: -0.106 \n",
      "Iteration 265/1000 - Loss: -0.149 \n",
      "Iteration 266/1000 - Loss: -0.145 \n",
      "Iteration 267/1000 - Loss: -0.112 \n",
      "Iteration 268/1000 - Loss: -0.097 \n",
      "Iteration 269/1000 - Loss: -0.122 \n",
      "Iteration 270/1000 - Loss: -0.162 \n",
      "Iteration 271/1000 - Loss: -0.174 \n",
      "Iteration 272/1000 - Loss: -0.157 \n",
      "Iteration 273/1000 - Loss: -0.134 \n",
      "Iteration 274/1000 - Loss: -0.131 \n",
      "Iteration 275/1000 - Loss: -0.154 \n",
      "Iteration 276/1000 - Loss: -0.183 \n",
      "Iteration 277/1000 - Loss: -0.194 \n",
      "Iteration 278/1000 - Loss: -0.184 \n",
      "Iteration 279/1000 - Loss: -0.167 \n",
      "Iteration 280/1000 - Loss: -0.157 \n",
      "Iteration 281/1000 - Loss: -0.161 \n",
      "Iteration 282/1000 - Loss: -0.180 \n",
      "Iteration 283/1000 - Loss: -0.201 \n",
      "Iteration 284/1000 - Loss: -0.210 \n",
      "Iteration 285/1000 - Loss: -0.205 \n",
      "Iteration 286/1000 - Loss: -0.193 \n",
      "Iteration 287/1000 - Loss: -0.183 \n",
      "Iteration 288/1000 - Loss: -0.180 \n",
      "Iteration 289/1000 - Loss: -0.187 \n",
      "Iteration 290/1000 - Loss: -0.201 \n",
      "Iteration 291/1000 - Loss: -0.215 \n",
      "Iteration 292/1000 - Loss: -0.223 \n",
      "Iteration 293/1000 - Loss: -0.223 \n",
      "Iteration 294/1000 - Loss: -0.217 \n",
      "Iteration 295/1000 - Loss: -0.209 \n",
      "Iteration 296/1000 - Loss: -0.204 \n",
      "Iteration 297/1000 - Loss: -0.200 \n",
      "Iteration 298/1000 - Loss: -0.200 \n",
      "Iteration 299/1000 - Loss: -0.207 \n",
      "Iteration 300/1000 - Loss: -0.217 \n",
      "Iteration 301/1000 - Loss: -0.226 \n",
      "Iteration 302/1000 - Loss: -0.233 \n",
      "Iteration 303/1000 - Loss: -0.235 \n",
      "Iteration 304/1000 - Loss: -0.234 \n",
      "Iteration 305/1000 - Loss: -0.231 \n",
      "Iteration 306/1000 - Loss: -0.227 \n",
      "Iteration 307/1000 - Loss: -0.223 \n",
      "Iteration 308/1000 - Loss: -0.217 \n",
      "Iteration 309/1000 - Loss: -0.214 \n",
      "Iteration 310/1000 - Loss: -0.211 \n",
      "Iteration 311/1000 - Loss: -0.212 \n",
      "Iteration 312/1000 - Loss: -0.218 \n",
      "Iteration 313/1000 - Loss: -0.225 \n",
      "Iteration 314/1000 - Loss: -0.233 \n",
      "Iteration 315/1000 - Loss: -0.241 \n",
      "Iteration 316/1000 - Loss: -0.245 \n",
      "Iteration 317/1000 - Loss: -0.245 \n",
      "Iteration 318/1000 - Loss: -0.243 \n",
      "Iteration 319/1000 - Loss: -0.239 \n",
      "Iteration 320/1000 - Loss: -0.236 \n",
      "Iteration 321/1000 - Loss: -0.233 \n",
      "Iteration 322/1000 - Loss: -0.230 \n",
      "Iteration 323/1000 - Loss: -0.230 \n",
      "Iteration 324/1000 - Loss: -0.231 \n",
      "Iteration 325/1000 - Loss: -0.233 \n",
      "Iteration 326/1000 - Loss: -0.236 \n",
      "Iteration 327/1000 - Loss: -0.241 \n",
      "Iteration 328/1000 - Loss: -0.245 \n",
      "Iteration 329/1000 - Loss: -0.248 \n",
      "Iteration 330/1000 - Loss: -0.251 \n",
      "Iteration 331/1000 - Loss: -0.252 \n",
      "Iteration 332/1000 - Loss: -0.252 \n",
      "Iteration 333/1000 - Loss: -0.251 \n",
      "Iteration 334/1000 - Loss: -0.250 \n",
      "Iteration 335/1000 - Loss: -0.249 \n",
      "Iteration 336/1000 - Loss: -0.246 \n",
      "Iteration 337/1000 - Loss: -0.244 \n",
      "Iteration 338/1000 - Loss: -0.242 \n",
      "Iteration 339/1000 - Loss: -0.238 \n",
      "Iteration 340/1000 - Loss: -0.234 \n",
      "Iteration 341/1000 - Loss: -0.231 \n",
      "Iteration 342/1000 - Loss: -0.229 \n",
      "Iteration 343/1000 - Loss: -0.227 \n",
      "Iteration 344/1000 - Loss: -0.230 \n",
      "Iteration 345/1000 - Loss: -0.235 \n",
      "Iteration 346/1000 - Loss: -0.243 \n",
      "Iteration 347/1000 - Loss: -0.250 \n",
      "Iteration 348/1000 - Loss: -0.256 \n",
      "Iteration 349/1000 - Loss: -0.258 \n",
      "Iteration 350/1000 - Loss: -0.256 \n",
      "Iteration 351/1000 - Loss: -0.254 \n",
      "Iteration 352/1000 - Loss: -0.250 \n",
      "Iteration 353/1000 - Loss: -0.247 \n",
      "Iteration 354/1000 - Loss: -0.244 \n",
      "Iteration 355/1000 - Loss: -0.244 \n",
      "Iteration 356/1000 - Loss: -0.247 \n",
      "Iteration 357/1000 - Loss: -0.250 \n",
      "Iteration 358/1000 - Loss: -0.254 \n",
      "Iteration 359/1000 - Loss: -0.257 \n",
      "Iteration 360/1000 - Loss: -0.260 \n",
      "Iteration 361/1000 - Loss: -0.261 \n",
      "Iteration 362/1000 - Loss: -0.260 \n",
      "Iteration 363/1000 - Loss: -0.259 \n",
      "Iteration 364/1000 - Loss: -0.257 \n",
      "Iteration 365/1000 - Loss: -0.256 \n",
      "Iteration 366/1000 - Loss: -0.255 \n",
      "Iteration 367/1000 - Loss: -0.255 \n",
      "Iteration 368/1000 - Loss: -0.254 \n",
      "Iteration 369/1000 - Loss: -0.254 \n",
      "Iteration 370/1000 - Loss: -0.254 \n",
      "Iteration 371/1000 - Loss: -0.255 \n",
      "Iteration 372/1000 - Loss: -0.256 \n",
      "Iteration 373/1000 - Loss: -0.256 \n",
      "Iteration 374/1000 - Loss: -0.258 \n",
      "Iteration 375/1000 - Loss: -0.259 \n",
      "Iteration 376/1000 - Loss: -0.260 \n",
      "Iteration 377/1000 - Loss: -0.261 \n",
      "Iteration 378/1000 - Loss: -0.262 \n",
      "Iteration 379/1000 - Loss: -0.262 \n",
      "Iteration 380/1000 - Loss: -0.263 \n",
      "Iteration 381/1000 - Loss: -0.263 \n",
      "Iteration 382/1000 - Loss: -0.263 \n",
      "Iteration 383/1000 - Loss: -0.264 \n",
      "Iteration 384/1000 - Loss: -0.264 \n",
      "Iteration 385/1000 - Loss: -0.264 \n",
      "Iteration 386/1000 - Loss: -0.264 \n",
      "Iteration 387/1000 - Loss: -0.264 \n",
      "Iteration 388/1000 - Loss: -0.263 \n",
      "Iteration 389/1000 - Loss: -0.263 \n",
      "Iteration 390/1000 - Loss: -0.261 \n",
      "Iteration 391/1000 - Loss: -0.260 \n",
      "Iteration 392/1000 - Loss: -0.257 \n",
      "Iteration 393/1000 - Loss: -0.252 \n",
      "Iteration 394/1000 - Loss: -0.244 \n",
      "Iteration 395/1000 - Loss: -0.228 \n",
      "Iteration 396/1000 - Loss: -0.206 \n",
      "Iteration 397/1000 - Loss: -0.180 \n",
      "Iteration 398/1000 - Loss: -0.165 \n",
      "Iteration 399/1000 - Loss: -0.175 \n",
      "Iteration 400/1000 - Loss: -0.217 \n",
      "Iteration 401/1000 - Loss: -0.257 \n",
      "Iteration 402/1000 - Loss: -0.264 \n",
      "Iteration 403/1000 - Loss: -0.238 \n",
      "Iteration 404/1000 - Loss: -0.215 \n",
      "Iteration 405/1000 - Loss: -0.223 \n",
      "Iteration 406/1000 - Loss: -0.252 \n",
      "Iteration 407/1000 - Loss: -0.266 \n",
      "Iteration 408/1000 - Loss: -0.255 \n",
      "Iteration 409/1000 - Loss: -0.238 \n",
      "Iteration 410/1000 - Loss: -0.241 \n",
      "Iteration 411/1000 - Loss: -0.258 \n",
      "Iteration 412/1000 - Loss: -0.266 \n",
      "Iteration 413/1000 - Loss: -0.259 \n",
      "Iteration 414/1000 - Loss: -0.250 \n",
      "Iteration 415/1000 - Loss: -0.252 \n",
      "Iteration 416/1000 - Loss: -0.262 \n",
      "Iteration 417/1000 - Loss: -0.267 \n",
      "Iteration 418/1000 - Loss: -0.262 \n",
      "Iteration 419/1000 - Loss: -0.257 \n",
      "Iteration 420/1000 - Loss: -0.258 \n",
      "Iteration 421/1000 - Loss: -0.264 \n",
      "Iteration 422/1000 - Loss: -0.267 \n",
      "Iteration 423/1000 - Loss: -0.265 \n",
      "Iteration 424/1000 - Loss: -0.261 \n",
      "Iteration 425/1000 - Loss: -0.262 \n",
      "Iteration 426/1000 - Loss: -0.266 \n",
      "Iteration 427/1000 - Loss: -0.269 \n",
      "Iteration 428/1000 - Loss: -0.267 \n",
      "Iteration 429/1000 - Loss: -0.264 \n",
      "Iteration 430/1000 - Loss: -0.265 \n",
      "Iteration 431/1000 - Loss: -0.266 \n",
      "Iteration 432/1000 - Loss: -0.269 \n",
      "Iteration 433/1000 - Loss: -0.268 \n",
      "Iteration 434/1000 - Loss: -0.266 \n",
      "Iteration 435/1000 - Loss: -0.265 \n",
      "Iteration 436/1000 - Loss: -0.267 \n",
      "Iteration 437/1000 - Loss: -0.268 \n",
      "Iteration 438/1000 - Loss: -0.268 \n",
      "Iteration 439/1000 - Loss: -0.267 \n",
      "Iteration 440/1000 - Loss: -0.267 \n",
      "Iteration 441/1000 - Loss: -0.267 \n",
      "Iteration 442/1000 - Loss: -0.269 \n",
      "Iteration 443/1000 - Loss: -0.270 \n",
      "Iteration 444/1000 - Loss: -0.269 \n",
      "Iteration 445/1000 - Loss: -0.269 \n",
      "Iteration 446/1000 - Loss: -0.268 \n",
      "Iteration 447/1000 - Loss: -0.269 \n",
      "Iteration 448/1000 - Loss: -0.269 \n",
      "Iteration 449/1000 - Loss: -0.270 \n",
      "Iteration 450/1000 - Loss: -0.270 \n",
      "Iteration 451/1000 - Loss: -0.269 \n",
      "Iteration 452/1000 - Loss: -0.269 \n",
      "Iteration 453/1000 - Loss: -0.269 \n",
      "Iteration 454/1000 - Loss: -0.269 \n",
      "Iteration 455/1000 - Loss: -0.269 \n",
      "Iteration 456/1000 - Loss: -0.270 \n",
      "Iteration 457/1000 - Loss: -0.269 \n",
      "Iteration 458/1000 - Loss: -0.269 \n",
      "Iteration 459/1000 - Loss: -0.270 \n",
      "Iteration 460/1000 - Loss: -0.271 \n",
      "Iteration 461/1000 - Loss: -0.270 \n",
      "Iteration 462/1000 - Loss: -0.271 \n",
      "Iteration 463/1000 - Loss: -0.271 \n",
      "Iteration 464/1000 - Loss: -0.271 \n",
      "Iteration 465/1000 - Loss: -0.271 \n",
      "Iteration 466/1000 - Loss: -0.271 \n",
      "Iteration 467/1000 - Loss: -0.270 \n",
      "Iteration 468/1000 - Loss: -0.270 \n",
      "Iteration 469/1000 - Loss: -0.270 \n",
      "Iteration 470/1000 - Loss: -0.270 \n",
      "Iteration 471/1000 - Loss: -0.271 \n",
      "Iteration 472/1000 - Loss: -0.271 \n",
      "Iteration 473/1000 - Loss: -0.271 \n",
      "Iteration 474/1000 - Loss: -0.271 \n",
      "Iteration 475/1000 - Loss: -0.271 \n",
      "Iteration 476/1000 - Loss: -0.271 \n",
      "Iteration 477/1000 - Loss: -0.271 \n",
      "Iteration 478/1000 - Loss: -0.271 \n",
      "Iteration 479/1000 - Loss: -0.270 \n",
      "Iteration 480/1000 - Loss: -0.271 \n",
      "Iteration 481/1000 - Loss: -0.272 \n",
      "Iteration 482/1000 - Loss: -0.272 \n",
      "Iteration 483/1000 - Loss: -0.272 \n",
      "Iteration 484/1000 - Loss: -0.272 \n",
      "Iteration 485/1000 - Loss: -0.272 \n",
      "Iteration 486/1000 - Loss: -0.272 \n",
      "Iteration 487/1000 - Loss: -0.272 \n",
      "Iteration 488/1000 - Loss: -0.272 \n",
      "Iteration 489/1000 - Loss: -0.272 \n",
      "Iteration 490/1000 - Loss: -0.271 \n",
      "Iteration 491/1000 - Loss: -0.272 \n",
      "Iteration 492/1000 - Loss: -0.271 \n",
      "Iteration 493/1000 - Loss: -0.272 \n",
      "Iteration 494/1000 - Loss: -0.272 \n",
      "Iteration 495/1000 - Loss: -0.272 \n",
      "Iteration 496/1000 - Loss: -0.272 \n",
      "Iteration 497/1000 - Loss: -0.272 \n",
      "Iteration 498/1000 - Loss: -0.272 \n",
      "Iteration 499/1000 - Loss: -0.272 \n",
      "Iteration 500/1000 - Loss: -0.271 \n",
      "Iteration 501/1000 - Loss: -0.271 \n",
      "Iteration 502/1000 - Loss: -0.271 \n",
      "Iteration 503/1000 - Loss: -0.271 \n",
      "Iteration 504/1000 - Loss: -0.271 \n",
      "Iteration 505/1000 - Loss: -0.269 \n",
      "Iteration 506/1000 - Loss: -0.269 \n",
      "Iteration 507/1000 - Loss: -0.267 \n",
      "Iteration 508/1000 - Loss: -0.263 \n",
      "Iteration 509/1000 - Loss: -0.258 \n",
      "Iteration 510/1000 - Loss: -0.249 \n",
      "Iteration 511/1000 - Loss: -0.234 \n",
      "Iteration 512/1000 - Loss: -0.212 \n",
      "Iteration 513/1000 - Loss: -0.188 \n",
      "Iteration 514/1000 - Loss: -0.171 \n",
      "Iteration 515/1000 - Loss: -0.177 \n",
      "Iteration 516/1000 - Loss: -0.210 \n",
      "Iteration 517/1000 - Loss: -0.252 \n",
      "Iteration 518/1000 - Loss: -0.273 \n",
      "Iteration 519/1000 - Loss: -0.262 \n",
      "Iteration 520/1000 - Loss: -0.238 \n",
      "Iteration 521/1000 - Loss: -0.227 \n",
      "Iteration 522/1000 - Loss: -0.241 \n",
      "Iteration 523/1000 - Loss: -0.263 \n",
      "Iteration 524/1000 - Loss: -0.272 \n",
      "Iteration 525/1000 - Loss: -0.263 \n",
      "Iteration 526/1000 - Loss: -0.249 \n",
      "Iteration 527/1000 - Loss: -0.248 \n",
      "Iteration 528/1000 - Loss: -0.261 \n",
      "Iteration 529/1000 - Loss: -0.272 \n",
      "Iteration 530/1000 - Loss: -0.270 \n",
      "Iteration 531/1000 - Loss: -0.262 \n",
      "Iteration 532/1000 - Loss: -0.258 \n",
      "Iteration 533/1000 - Loss: -0.263 \n",
      "Iteration 534/1000 - Loss: -0.271 \n",
      "Iteration 535/1000 - Loss: -0.272 \n",
      "Iteration 536/1000 - Loss: -0.269 \n",
      "Iteration 537/1000 - Loss: -0.265 \n",
      "Iteration 538/1000 - Loss: -0.266 \n",
      "Iteration 539/1000 - Loss: -0.270 \n",
      "Iteration 540/1000 - Loss: -0.273 \n",
      "Iteration 541/1000 - Loss: -0.271 \n",
      "Iteration 542/1000 - Loss: -0.268 \n",
      "Iteration 543/1000 - Loss: -0.270 \n",
      "Iteration 544/1000 - Loss: -0.271 \n",
      "Iteration 545/1000 - Loss: -0.273 \n",
      "Iteration 546/1000 - Loss: -0.273 \n",
      "Iteration 547/1000 - Loss: -0.272 \n",
      "Iteration 548/1000 - Loss: -0.271 \n",
      "Iteration 549/1000 - Loss: -0.272 \n",
      "Iteration 550/1000 - Loss: -0.273 \n",
      "Iteration 551/1000 - Loss: -0.273 \n",
      "Iteration 552/1000 - Loss: -0.274 \n",
      "Iteration 553/1000 - Loss: -0.272 \n",
      "Iteration 554/1000 - Loss: -0.272 \n",
      "Iteration 555/1000 - Loss: -0.272 \n",
      "Iteration 556/1000 - Loss: -0.273 \n",
      "Iteration 557/1000 - Loss: -0.273 \n",
      "Iteration 558/1000 - Loss: -0.273 \n",
      "Iteration 559/1000 - Loss: -0.273 \n",
      "Iteration 560/1000 - Loss: -0.273 \n",
      "Iteration 561/1000 - Loss: -0.273 \n",
      "Iteration 562/1000 - Loss: -0.273 \n",
      "Iteration 563/1000 - Loss: -0.274 \n",
      "Iteration 564/1000 - Loss: -0.274 \n",
      "Iteration 565/1000 - Loss: -0.273 \n",
      "Iteration 566/1000 - Loss: -0.274 \n",
      "Iteration 567/1000 - Loss: -0.273 \n",
      "Iteration 568/1000 - Loss: -0.273 \n",
      "Iteration 569/1000 - Loss: -0.274 \n",
      "Iteration 570/1000 - Loss: -0.274 \n",
      "Iteration 571/1000 - Loss: -0.274 \n",
      "Iteration 572/1000 - Loss: -0.274 \n",
      "Iteration 573/1000 - Loss: -0.274 \n",
      "Iteration 574/1000 - Loss: -0.273 \n",
      "Iteration 575/1000 - Loss: -0.274 \n",
      "Iteration 576/1000 - Loss: -0.274 \n",
      "Iteration 577/1000 - Loss: -0.274 \n",
      "Iteration 578/1000 - Loss: -0.274 \n",
      "Iteration 579/1000 - Loss: -0.273 \n",
      "Iteration 580/1000 - Loss: -0.274 \n",
      "Iteration 581/1000 - Loss: -0.273 \n",
      "Iteration 582/1000 - Loss: -0.274 \n",
      "Iteration 583/1000 - Loss: -0.274 \n",
      "Iteration 584/1000 - Loss: -0.274 \n",
      "Iteration 585/1000 - Loss: -0.274 \n",
      "Iteration 586/1000 - Loss: -0.274 \n",
      "Iteration 587/1000 - Loss: -0.274 \n",
      "Iteration 588/1000 - Loss: -0.273 \n",
      "Iteration 589/1000 - Loss: -0.275 \n",
      "Iteration 590/1000 - Loss: -0.274 \n",
      "Iteration 591/1000 - Loss: -0.275 \n",
      "Iteration 592/1000 - Loss: -0.275 \n",
      "Iteration 593/1000 - Loss: -0.275 \n",
      "Iteration 594/1000 - Loss: -0.276 \n",
      "Iteration 595/1000 - Loss: -0.275 \n",
      "Iteration 596/1000 - Loss: -0.275 \n",
      "Iteration 597/1000 - Loss: -0.275 \n",
      "Iteration 598/1000 - Loss: -0.275 \n",
      "Iteration 599/1000 - Loss: -0.274 \n",
      "Iteration 600/1000 - Loss: -0.275 \n",
      "Iteration 601/1000 - Loss: -0.274 \n",
      "Iteration 602/1000 - Loss: -0.275 \n",
      "Iteration 603/1000 - Loss: -0.275 \n",
      "Iteration 604/1000 - Loss: -0.275 \n",
      "Iteration 605/1000 - Loss: -0.275 \n",
      "Iteration 606/1000 - Loss: -0.275 \n",
      "Iteration 607/1000 - Loss: -0.275 \n",
      "Iteration 608/1000 - Loss: -0.275 \n",
      "Iteration 609/1000 - Loss: -0.275 \n",
      "Iteration 610/1000 - Loss: -0.275 \n",
      "Iteration 611/1000 - Loss: -0.275 \n",
      "Iteration 612/1000 - Loss: -0.275 \n",
      "Iteration 613/1000 - Loss: -0.275 \n",
      "Iteration 614/1000 - Loss: -0.275 \n",
      "Iteration 615/1000 - Loss: -0.275 \n",
      "Iteration 616/1000 - Loss: -0.275 \n",
      "Iteration 617/1000 - Loss: -0.275 \n",
      "Iteration 618/1000 - Loss: -0.275 \n",
      "Iteration 619/1000 - Loss: -0.275 \n",
      "Iteration 620/1000 - Loss: -0.275 \n",
      "Iteration 621/1000 - Loss: -0.275 \n",
      "Iteration 622/1000 - Loss: -0.275 \n",
      "Iteration 623/1000 - Loss: -0.275 \n",
      "Iteration 624/1000 - Loss: -0.275 \n",
      "Iteration 625/1000 - Loss: -0.275 \n",
      "Iteration 626/1000 - Loss: -0.276 \n",
      "Iteration 627/1000 - Loss: -0.275 \n",
      "Iteration 628/1000 - Loss: -0.275 \n",
      "Iteration 629/1000 - Loss: -0.275 \n",
      "Iteration 630/1000 - Loss: -0.275 \n",
      "Iteration 631/1000 - Loss: -0.275 \n",
      "Iteration 632/1000 - Loss: -0.275 \n",
      "Iteration 633/1000 - Loss: -0.275 \n",
      "Iteration 634/1000 - Loss: -0.275 \n",
      "Iteration 635/1000 - Loss: -0.275 \n",
      "Iteration 636/1000 - Loss: -0.274 \n",
      "Iteration 637/1000 - Loss: -0.274 \n",
      "Iteration 638/1000 - Loss: -0.273 \n",
      "Iteration 639/1000 - Loss: -0.271 \n",
      "Iteration 640/1000 - Loss: -0.267 \n",
      "Iteration 641/1000 - Loss: -0.261 \n",
      "Iteration 642/1000 - Loss: -0.251 \n",
      "Iteration 643/1000 - Loss: -0.234 \n",
      "Iteration 644/1000 - Loss: -0.207 \n",
      "Iteration 645/1000 - Loss: -0.172 \n",
      "Iteration 646/1000 - Loss: -0.140 \n",
      "Iteration 647/1000 - Loss: -0.136 \n",
      "Iteration 648/1000 - Loss: -0.177 \n",
      "Iteration 649/1000 - Loss: -0.240 \n",
      "Iteration 650/1000 - Loss: -0.275 \n",
      "Iteration 651/1000 - Loss: -0.258 \n",
      "Iteration 652/1000 - Loss: -0.221 \n",
      "Iteration 653/1000 - Loss: -0.208 \n",
      "Iteration 654/1000 - Loss: -0.235 \n",
      "Iteration 655/1000 - Loss: -0.268 \n",
      "Iteration 656/1000 - Loss: -0.272 \n",
      "Iteration 657/1000 - Loss: -0.253 \n",
      "Iteration 658/1000 - Loss: -0.239 \n",
      "Iteration 659/1000 - Loss: -0.249 \n",
      "Iteration 660/1000 - Loss: -0.270 \n",
      "Iteration 661/1000 - Loss: -0.276 \n",
      "Iteration 662/1000 - Loss: -0.263 \n",
      "Iteration 663/1000 - Loss: -0.253 \n",
      "Iteration 664/1000 - Loss: -0.259 \n",
      "Iteration 665/1000 - Loss: -0.272 \n",
      "Iteration 666/1000 - Loss: -0.275 \n",
      "Iteration 667/1000 - Loss: -0.268 \n",
      "Iteration 668/1000 - Loss: -0.262 \n",
      "Iteration 669/1000 - Loss: -0.267 \n",
      "Iteration 670/1000 - Loss: -0.274 \n",
      "Iteration 671/1000 - Loss: -0.276 \n",
      "Iteration 672/1000 - Loss: -0.271 \n",
      "Iteration 673/1000 - Loss: -0.267 \n",
      "Iteration 674/1000 - Loss: -0.270 \n",
      "Iteration 675/1000 - Loss: -0.275 \n",
      "Iteration 676/1000 - Loss: -0.276 \n",
      "Iteration 677/1000 - Loss: -0.273 \n",
      "Iteration 678/1000 - Loss: -0.271 \n",
      "Iteration 679/1000 - Loss: -0.272 \n",
      "Iteration 680/1000 - Loss: -0.276 \n",
      "Iteration 681/1000 - Loss: -0.276 \n",
      "Iteration 682/1000 - Loss: -0.274 \n",
      "Iteration 683/1000 - Loss: -0.273 \n",
      "Iteration 684/1000 - Loss: -0.274 \n",
      "Iteration 685/1000 - Loss: -0.275 \n",
      "Iteration 686/1000 - Loss: -0.276 \n",
      "Iteration 687/1000 - Loss: -0.275 \n",
      "Iteration 688/1000 - Loss: -0.274 \n",
      "Iteration 689/1000 - Loss: -0.275 \n",
      "Iteration 690/1000 - Loss: -0.275 \n",
      "Iteration 691/1000 - Loss: -0.276 \n",
      "Iteration 692/1000 - Loss: -0.275 \n",
      "Iteration 693/1000 - Loss: -0.275 \n",
      "Iteration 694/1000 - Loss: -0.275 \n",
      "Iteration 695/1000 - Loss: -0.275 \n",
      "Iteration 696/1000 - Loss: -0.276 \n",
      "Iteration 697/1000 - Loss: -0.275 \n",
      "Iteration 698/1000 - Loss: -0.275 \n",
      "Iteration 699/1000 - Loss: -0.275 \n",
      "Iteration 700/1000 - Loss: -0.275 \n",
      "Iteration 701/1000 - Loss: -0.275 \n",
      "Iteration 702/1000 - Loss: -0.276 \n",
      "Iteration 703/1000 - Loss: -0.276 \n",
      "Iteration 704/1000 - Loss: -0.276 \n",
      "Iteration 705/1000 - Loss: -0.275 \n",
      "Iteration 706/1000 - Loss: -0.276 \n",
      "Iteration 707/1000 - Loss: -0.276 \n",
      "Iteration 708/1000 - Loss: -0.276 \n",
      "Iteration 709/1000 - Loss: -0.276 \n",
      "Iteration 710/1000 - Loss: -0.276 \n",
      "Iteration 711/1000 - Loss: -0.276 \n",
      "Iteration 712/1000 - Loss: -0.276 \n",
      "Iteration 713/1000 - Loss: -0.276 \n",
      "Iteration 714/1000 - Loss: -0.276 \n",
      "Iteration 715/1000 - Loss: -0.276 \n",
      "Iteration 716/1000 - Loss: -0.276 \n",
      "Iteration 717/1000 - Loss: -0.276 \n",
      "Iteration 718/1000 - Loss: -0.276 \n",
      "Iteration 719/1000 - Loss: -0.275 \n",
      "Iteration 720/1000 - Loss: -0.276 \n",
      "Iteration 721/1000 - Loss: -0.276 \n",
      "Iteration 722/1000 - Loss: -0.276 \n",
      "Iteration 723/1000 - Loss: -0.276 \n",
      "Iteration 724/1000 - Loss: -0.276 \n",
      "Iteration 725/1000 - Loss: -0.276 \n",
      "Iteration 726/1000 - Loss: -0.276 \n",
      "Iteration 727/1000 - Loss: -0.276 \n",
      "Iteration 728/1000 - Loss: -0.276 \n",
      "Iteration 729/1000 - Loss: -0.276 \n",
      "Iteration 730/1000 - Loss: -0.276 \n",
      "Iteration 731/1000 - Loss: -0.276 \n",
      "Iteration 732/1000 - Loss: -0.276 \n",
      "Iteration 733/1000 - Loss: -0.276 \n",
      "Iteration 734/1000 - Loss: -0.276 \n",
      "Iteration 735/1000 - Loss: -0.276 \n",
      "Iteration 736/1000 - Loss: -0.276 \n",
      "Iteration 737/1000 - Loss: -0.275 \n",
      "Iteration 738/1000 - Loss: -0.275 \n",
      "Iteration 739/1000 - Loss: -0.276 \n",
      "Iteration 740/1000 - Loss: -0.276 \n",
      "Iteration 741/1000 - Loss: -0.276 \n",
      "Iteration 742/1000 - Loss: -0.276 \n",
      "Iteration 743/1000 - Loss: -0.276 \n",
      "Iteration 744/1000 - Loss: -0.276 \n",
      "Iteration 745/1000 - Loss: -0.276 \n",
      "Iteration 746/1000 - Loss: -0.276 \n",
      "Iteration 747/1000 - Loss: -0.276 \n",
      "Iteration 748/1000 - Loss: -0.276 \n",
      "Iteration 749/1000 - Loss: -0.276 \n",
      "Iteration 750/1000 - Loss: -0.276 \n",
      "Iteration 751/1000 - Loss: -0.277 \n",
      "Iteration 752/1000 - Loss: -0.276 \n",
      "Iteration 753/1000 - Loss: -0.276 \n",
      "Iteration 754/1000 - Loss: -0.276 \n",
      "Iteration 755/1000 - Loss: -0.276 \n",
      "Iteration 756/1000 - Loss: -0.276 \n",
      "Iteration 757/1000 - Loss: -0.276 \n",
      "Iteration 758/1000 - Loss: -0.276 \n",
      "Iteration 759/1000 - Loss: -0.276 \n",
      "Iteration 760/1000 - Loss: -0.276 \n",
      "Iteration 761/1000 - Loss: -0.276 \n",
      "Iteration 762/1000 - Loss: -0.276 \n",
      "Iteration 763/1000 - Loss: -0.277 \n",
      "Iteration 764/1000 - Loss: -0.277 \n",
      "Iteration 765/1000 - Loss: -0.277 \n",
      "Iteration 766/1000 - Loss: -0.277 \n",
      "Iteration 767/1000 - Loss: -0.277 \n",
      "Iteration 768/1000 - Loss: -0.277 \n",
      "Iteration 769/1000 - Loss: -0.277 \n",
      "Iteration 770/1000 - Loss: -0.277 \n",
      "Iteration 771/1000 - Loss: -0.277 \n",
      "Iteration 772/1000 - Loss: -0.277 \n",
      "Iteration 773/1000 - Loss: -0.278 \n",
      "Iteration 774/1000 - Loss: -0.277 \n",
      "Iteration 775/1000 - Loss: -0.277 \n",
      "Iteration 776/1000 - Loss: -0.277 \n",
      "Iteration 777/1000 - Loss: -0.277 \n",
      "Iteration 778/1000 - Loss: -0.277 \n",
      "Iteration 779/1000 - Loss: -0.277 \n",
      "Iteration 780/1000 - Loss: -0.277 \n",
      "Iteration 781/1000 - Loss: -0.278 \n",
      "Iteration 782/1000 - Loss: -0.276 \n",
      "Iteration 783/1000 - Loss: -0.277 \n",
      "Iteration 784/1000 - Loss: -0.277 \n",
      "Iteration 785/1000 - Loss: -0.277 \n",
      "Iteration 786/1000 - Loss: -0.277 \n",
      "Iteration 787/1000 - Loss: -0.277 \n",
      "Iteration 788/1000 - Loss: -0.277 \n",
      "Iteration 789/1000 - Loss: -0.278 \n",
      "Iteration 790/1000 - Loss: -0.277 \n",
      "Iteration 791/1000 - Loss: -0.277 \n",
      "Iteration 792/1000 - Loss: -0.277 \n",
      "Iteration 793/1000 - Loss: -0.277 \n",
      "Iteration 794/1000 - Loss: -0.277 \n",
      "Iteration 795/1000 - Loss: -0.277 \n",
      "Iteration 796/1000 - Loss: -0.277 \n",
      "Iteration 797/1000 - Loss: -0.277 \n",
      "Iteration 798/1000 - Loss: -0.277 \n",
      "Iteration 799/1000 - Loss: -0.277 \n",
      "Iteration 800/1000 - Loss: -0.277 \n",
      "Iteration 801/1000 - Loss: -0.277 \n",
      "Iteration 802/1000 - Loss: -0.276 \n",
      "Iteration 803/1000 - Loss: -0.276 \n",
      "Iteration 804/1000 - Loss: -0.275 \n",
      "Iteration 805/1000 - Loss: -0.274 \n",
      "Iteration 806/1000 - Loss: -0.271 \n",
      "Iteration 807/1000 - Loss: -0.268 \n",
      "Iteration 808/1000 - Loss: -0.260 \n",
      "Iteration 809/1000 - Loss: -0.250 \n",
      "Iteration 810/1000 - Loss: -0.233 \n",
      "Iteration 811/1000 - Loss: -0.208 \n",
      "Iteration 812/1000 - Loss: -0.178 \n",
      "Iteration 813/1000 - Loss: -0.147 \n",
      "Iteration 814/1000 - Loss: -0.139 \n",
      "Iteration 815/1000 - Loss: -0.170 \n",
      "Iteration 816/1000 - Loss: -0.228 \n",
      "Iteration 817/1000 - Loss: -0.271 \n",
      "Iteration 818/1000 - Loss: -0.272 \n",
      "Iteration 819/1000 - Loss: -0.243 \n",
      "Iteration 820/1000 - Loss: -0.217 \n",
      "Iteration 821/1000 - Loss: -0.224 \n",
      "Iteration 822/1000 - Loss: -0.254 \n",
      "Iteration 823/1000 - Loss: -0.276 \n",
      "Iteration 824/1000 - Loss: -0.270 \n",
      "Iteration 825/1000 - Loss: -0.251 \n",
      "Iteration 826/1000 - Loss: -0.244 \n",
      "Iteration 827/1000 - Loss: -0.256 \n",
      "Iteration 828/1000 - Loss: -0.273 \n",
      "Iteration 829/1000 - Loss: -0.275 \n",
      "Iteration 830/1000 - Loss: -0.265 \n",
      "Iteration 831/1000 - Loss: -0.257 \n",
      "Iteration 832/1000 - Loss: -0.262 \n",
      "Iteration 833/1000 - Loss: -0.273 \n",
      "Iteration 834/1000 - Loss: -0.277 \n",
      "Iteration 835/1000 - Loss: -0.272 \n",
      "Iteration 836/1000 - Loss: -0.266 \n",
      "Iteration 837/1000 - Loss: -0.268 \n",
      "Iteration 838/1000 - Loss: -0.274 \n",
      "Iteration 839/1000 - Loss: -0.277 \n",
      "Iteration 840/1000 - Loss: -0.275 \n",
      "Iteration 841/1000 - Loss: -0.272 \n",
      "Iteration 842/1000 - Loss: -0.271 \n",
      "Iteration 843/1000 - Loss: -0.273 \n",
      "Iteration 844/1000 - Loss: -0.277 \n",
      "Iteration 845/1000 - Loss: -0.276 \n",
      "Iteration 846/1000 - Loss: -0.274 \n",
      "Iteration 847/1000 - Loss: -0.273 \n",
      "Iteration 848/1000 - Loss: -0.275 \n",
      "Iteration 849/1000 - Loss: -0.277 \n",
      "Iteration 850/1000 - Loss: -0.277 \n",
      "Iteration 851/1000 - Loss: -0.276 \n",
      "Iteration 852/1000 - Loss: -0.275 \n",
      "Iteration 853/1000 - Loss: -0.275 \n",
      "Iteration 854/1000 - Loss: -0.276 \n",
      "Iteration 855/1000 - Loss: -0.277 \n",
      "Iteration 856/1000 - Loss: -0.277 \n",
      "Iteration 857/1000 - Loss: -0.276 \n",
      "Iteration 858/1000 - Loss: -0.276 \n",
      "Iteration 859/1000 - Loss: -0.276 \n",
      "Iteration 860/1000 - Loss: -0.277 \n",
      "Iteration 861/1000 - Loss: -0.277 \n",
      "Iteration 862/1000 - Loss: -0.277 \n",
      "Iteration 863/1000 - Loss: -0.277 \n",
      "Iteration 864/1000 - Loss: -0.276 \n",
      "Iteration 865/1000 - Loss: -0.277 \n",
      "Iteration 866/1000 - Loss: -0.277 \n",
      "Iteration 867/1000 - Loss: -0.277 \n",
      "Iteration 868/1000 - Loss: -0.277 \n",
      "Iteration 869/1000 - Loss: -0.277 \n",
      "Iteration 870/1000 - Loss: -0.277 \n",
      "Iteration 871/1000 - Loss: -0.276 \n",
      "Iteration 872/1000 - Loss: -0.278 \n",
      "Iteration 873/1000 - Loss: -0.277 \n",
      "Iteration 874/1000 - Loss: -0.277 \n",
      "Iteration 875/1000 - Loss: -0.277 \n",
      "Iteration 876/1000 - Loss: -0.277 \n",
      "Iteration 877/1000 - Loss: -0.277 \n",
      "Iteration 878/1000 - Loss: -0.277 \n",
      "Iteration 879/1000 - Loss: -0.277 \n",
      "Iteration 880/1000 - Loss: -0.277 \n",
      "Iteration 881/1000 - Loss: -0.277 \n",
      "Iteration 882/1000 - Loss: -0.277 \n",
      "Iteration 883/1000 - Loss: -0.276 \n",
      "Iteration 884/1000 - Loss: -0.277 \n",
      "Iteration 885/1000 - Loss: -0.278 \n",
      "Iteration 886/1000 - Loss: -0.277 \n",
      "Iteration 887/1000 - Loss: -0.277 \n",
      "Iteration 888/1000 - Loss: -0.277 \n",
      "Iteration 889/1000 - Loss: -0.277 \n",
      "Iteration 890/1000 - Loss: -0.277 \n",
      "Iteration 891/1000 - Loss: -0.277 \n",
      "Iteration 892/1000 - Loss: -0.277 \n",
      "Iteration 893/1000 - Loss: -0.277 \n",
      "Iteration 894/1000 - Loss: -0.277 \n",
      "Iteration 895/1000 - Loss: -0.277 \n",
      "Iteration 896/1000 - Loss: -0.277 \n",
      "Iteration 897/1000 - Loss: -0.277 \n",
      "Iteration 898/1000 - Loss: -0.277 \n",
      "Iteration 899/1000 - Loss: -0.277 \n",
      "Iteration 900/1000 - Loss: -0.277 \n",
      "Iteration 901/1000 - Loss: -0.277 \n",
      "Iteration 902/1000 - Loss: -0.277 \n",
      "Iteration 903/1000 - Loss: -0.277 \n",
      "Iteration 904/1000 - Loss: -0.277 \n",
      "Iteration 905/1000 - Loss: -0.277 \n",
      "Iteration 906/1000 - Loss: -0.277 \n",
      "Iteration 907/1000 - Loss: -0.277 \n",
      "Iteration 908/1000 - Loss: -0.277 \n",
      "Iteration 909/1000 - Loss: -0.277 \n",
      "Iteration 910/1000 - Loss: -0.277 \n",
      "Iteration 911/1000 - Loss: -0.277 \n",
      "Iteration 912/1000 - Loss: -0.277 \n",
      "Iteration 913/1000 - Loss: -0.277 \n",
      "Iteration 914/1000 - Loss: -0.277 \n",
      "Iteration 915/1000 - Loss: -0.277 \n",
      "Iteration 916/1000 - Loss: -0.277 \n",
      "Iteration 917/1000 - Loss: -0.277 \n",
      "Iteration 918/1000 - Loss: -0.277 \n",
      "Iteration 919/1000 - Loss: -0.278 \n",
      "Iteration 920/1000 - Loss: -0.277 \n",
      "Iteration 921/1000 - Loss: -0.277 \n",
      "Iteration 922/1000 - Loss: -0.277 \n",
      "Iteration 923/1000 - Loss: -0.277 \n",
      "Iteration 924/1000 - Loss: -0.277 \n",
      "Iteration 925/1000 - Loss: -0.278 \n",
      "Iteration 926/1000 - Loss: -0.277 \n",
      "Iteration 927/1000 - Loss: -0.278 \n",
      "Iteration 928/1000 - Loss: -0.277 \n",
      "Iteration 929/1000 - Loss: -0.277 \n",
      "Iteration 930/1000 - Loss: -0.277 \n",
      "Iteration 931/1000 - Loss: -0.277 \n",
      "Iteration 932/1000 - Loss: -0.277 \n",
      "Iteration 933/1000 - Loss: -0.277 \n",
      "Iteration 934/1000 - Loss: -0.278 \n",
      "Iteration 935/1000 - Loss: -0.277 \n",
      "Iteration 936/1000 - Loss: -0.277 \n",
      "Iteration 937/1000 - Loss: -0.277 \n",
      "Iteration 938/1000 - Loss: -0.276 \n",
      "Iteration 939/1000 - Loss: -0.277 \n",
      "Iteration 940/1000 - Loss: -0.277 \n",
      "Iteration 941/1000 - Loss: -0.277 \n",
      "Iteration 942/1000 - Loss: -0.278 \n",
      "Iteration 943/1000 - Loss: -0.277 \n",
      "Iteration 944/1000 - Loss: -0.278 \n",
      "Iteration 945/1000 - Loss: -0.277 \n",
      "Iteration 946/1000 - Loss: -0.277 \n",
      "Iteration 947/1000 - Loss: -0.277 \n",
      "Iteration 948/1000 - Loss: -0.278 \n",
      "Iteration 949/1000 - Loss: -0.277 \n",
      "Iteration 950/1000 - Loss: -0.278 \n",
      "Iteration 951/1000 - Loss: -0.277 \n",
      "Iteration 952/1000 - Loss: -0.277 \n",
      "Iteration 953/1000 - Loss: -0.277 \n",
      "Iteration 954/1000 - Loss: -0.277 \n",
      "Iteration 955/1000 - Loss: -0.277 \n",
      "Iteration 956/1000 - Loss: -0.277 \n",
      "Iteration 957/1000 - Loss: -0.277 \n",
      "Iteration 958/1000 - Loss: -0.277 \n",
      "Iteration 959/1000 - Loss: -0.279 \n",
      "Iteration 960/1000 - Loss: -0.279 \n",
      "Iteration 961/1000 - Loss: -0.278 \n",
      "Iteration 962/1000 - Loss: -0.279 \n",
      "Iteration 963/1000 - Loss: -0.279 \n",
      "Iteration 964/1000 - Loss: -0.278 \n",
      "Iteration 965/1000 - Loss: -0.279 \n",
      "Iteration 966/1000 - Loss: -0.278 \n",
      "Iteration 967/1000 - Loss: -0.278 \n",
      "Iteration 968/1000 - Loss: -0.279 \n",
      "Iteration 969/1000 - Loss: -0.278 \n",
      "Iteration 970/1000 - Loss: -0.278 \n",
      "Iteration 971/1000 - Loss: -0.279 \n",
      "Iteration 972/1000 - Loss: -0.278 \n",
      "Iteration 973/1000 - Loss: -0.278 \n",
      "Iteration 974/1000 - Loss: -0.277 \n",
      "Iteration 975/1000 - Loss: -0.277 \n",
      "Iteration 976/1000 - Loss: -0.277 \n",
      "Iteration 977/1000 - Loss: -0.275 \n",
      "Iteration 978/1000 - Loss: -0.273 \n",
      "Iteration 979/1000 - Loss: -0.269 \n",
      "Iteration 980/1000 - Loss: -0.263 \n",
      "Iteration 981/1000 - Loss: -0.253 \n",
      "Iteration 982/1000 - Loss: -0.238 \n",
      "Iteration 983/1000 - Loss: -0.216 \n",
      "Iteration 984/1000 - Loss: -0.187 \n",
      "Iteration 985/1000 - Loss: -0.156 \n",
      "Iteration 986/1000 - Loss: -0.137 \n",
      "Iteration 987/1000 - Loss: -0.146 \n",
      "Iteration 988/1000 - Loss: -0.191 \n",
      "Iteration 989/1000 - Loss: -0.248 \n",
      "Iteration 990/1000 - Loss: -0.277 \n",
      "Iteration 991/1000 - Loss: -0.265 \n",
      "Iteration 992/1000 - Loss: -0.232 \n",
      "Iteration 993/1000 - Loss: -0.214 \n",
      "Iteration 994/1000 - Loss: -0.230 \n",
      "Iteration 995/1000 - Loss: -0.262 \n",
      "Iteration 996/1000 - Loss: -0.277 \n",
      "Iteration 997/1000 - Loss: -0.269 \n",
      "Iteration 998/1000 - Loss: -0.250 \n",
      "Iteration 999/1000 - Loss: -0.246 \n",
      "Iteration 1000/1000 - Loss: -0.260 \n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "hogde_gp.train(model, likelihood, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.012508535757660866\n",
      "Test MSE: 0.001972610130906105\n",
      "Test R2: 0.9996838569641113\n",
      "Test MLSS: -3.0074620246887207\n",
      "Test NLPD: -3.514639377593994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([168]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "hogde_gp.predict(model, likelihood, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
