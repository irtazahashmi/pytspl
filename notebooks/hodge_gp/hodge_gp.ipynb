{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hodge-Compositional Edge Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set the current working directory\n",
    "curr_path = os.getcwd().split(\"/\")[:-2]\n",
    "curr_path = \"/\".join(curr_path)\n",
    "os.chdir(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No coordinates found.\n",
      "Generating coordinates using spring layout.\n",
      "Num. of nodes: 25\n",
      "Num. of edges: 210\n",
      "Num. of triangles: 770\n",
      "Shape: (25, 210, 770)\n",
      "Max Dimension: 2\n",
      "Coordinates: 25\n",
      "Flow: 210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# read dataset\n",
    "from pytspl import load_dataset\n",
    "\n",
    "sc, _, flow = load_dataset(\"forex\")\n",
    "\n",
    "# get the y from flow dict\n",
    "y = np.fromiter(flow.values(), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytspl.hogde_gp import HodgeGPTrainer\n",
    "\n",
    "# create the trainer object\n",
    "hogde_gp = HodgeGPTrainer(sc = sc, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (42,)\n",
      "x_test: (168,)\n",
      "y_train: (42,)\n",
      "y_test: (168,)\n"
     ]
    }
   ],
   "source": [
    "# set the training ratio\n",
    "train_ratio = 0.2\n",
    "# set the data normalization\n",
    "data_normalization = False\n",
    "\n",
    "# get the eigenpairs\n",
    "eigenpairs = hogde_gp.get_eigenpairs()\n",
    "\n",
    "# split the data into training and testing sets\n",
    "x_train, y_train, x_test, y_test, x, y  = hogde_gp.train_test_split(train_ratio=train_ratio, data_normalization=data_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(32.), tensor(4.5767))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytspl.hogde_gp.kernel_serializer import KernelSerializer\n",
    "\n",
    "# set the kernel parameters\n",
    "\n",
    "kernel_type = \"matern\" # kernel type\n",
    "data_name = \"forex\" # data set name\n",
    "\n",
    "# serialize the kernel\n",
    "kernel = KernelSerializer().serialize(eigenpairs=eigenpairs, kernel_type=kernel_type, data_name=data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from pytspl.hogde_gp import ExactGPModel\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train, y_train, likelihood, kernel, mean_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytspl.hogde_gp.forex.matern.MaternKernelForex"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "output_device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   model = model.to(output_device)\n",
    "   likelihood = likelihood.to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: likelihood.noise_covar.raw_noise                   value = 0.0\n",
      "Parameter name: mean_module.raw_constant                           value = 0.0\n",
      "Parameter name: covar_module.raw_outputscale                       value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_kappa_down            value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_kappa_up              value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_kappa                 value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_mu                    value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_mu_down               value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_mu_up                 value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_h                     value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_h_down                value = 0.0\n",
      "Parameter name: covar_module.base_kernel.raw_h_up                  value = 0.0\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:50} value = {param.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1000 - Loss: 5.387 \n",
      "Iteration 2/1000 - Loss: 4.940 \n",
      "Iteration 3/1000 - Loss: 4.554 \n",
      "Iteration 4/1000 - Loss: 4.221 \n",
      "Iteration 5/1000 - Loss: 3.936 \n",
      "Iteration 6/1000 - Loss: 3.691 \n",
      "Iteration 7/1000 - Loss: 3.482 \n",
      "Iteration 8/1000 - Loss: 3.303 \n",
      "Iteration 9/1000 - Loss: 3.150 \n",
      "Iteration 10/1000 - Loss: 3.018 \n",
      "Iteration 11/1000 - Loss: 2.906 \n",
      "Iteration 12/1000 - Loss: 2.811 \n",
      "Iteration 13/1000 - Loss: 2.729 \n",
      "Iteration 14/1000 - Loss: 2.660 \n",
      "Iteration 15/1000 - Loss: 2.602 \n",
      "Iteration 16/1000 - Loss: 2.553 \n",
      "Iteration 17/1000 - Loss: 2.512 \n",
      "Iteration 18/1000 - Loss: 2.478 \n",
      "Iteration 19/1000 - Loss: 2.451 \n",
      "Iteration 20/1000 - Loss: 2.428 \n",
      "Iteration 21/1000 - Loss: 2.409 \n",
      "Iteration 22/1000 - Loss: 2.394 \n",
      "Iteration 23/1000 - Loss: 2.382 \n",
      "Iteration 24/1000 - Loss: 2.373 \n",
      "Iteration 25/1000 - Loss: 2.365 \n",
      "Iteration 26/1000 - Loss: 2.359 \n",
      "Iteration 27/1000 - Loss: 2.354 \n",
      "Iteration 28/1000 - Loss: 2.350 \n",
      "Iteration 29/1000 - Loss: 2.346 \n",
      "Iteration 30/1000 - Loss: 2.344 \n",
      "Iteration 31/1000 - Loss: 2.341 \n",
      "Iteration 32/1000 - Loss: 2.339 \n",
      "Iteration 33/1000 - Loss: 2.337 \n",
      "Iteration 34/1000 - Loss: 2.336 \n",
      "Iteration 35/1000 - Loss: 2.334 \n",
      "Iteration 36/1000 - Loss: 2.332 \n",
      "Iteration 37/1000 - Loss: 2.330 \n",
      "Iteration 38/1000 - Loss: 2.328 \n",
      "Iteration 39/1000 - Loss: 2.326 \n",
      "Iteration 40/1000 - Loss: 2.324 \n",
      "Iteration 41/1000 - Loss: 2.322 \n",
      "Iteration 42/1000 - Loss: 2.319 \n",
      "Iteration 43/1000 - Loss: 2.317 \n",
      "Iteration 44/1000 - Loss: 2.314 \n",
      "Iteration 45/1000 - Loss: 2.311 \n",
      "Iteration 46/1000 - Loss: 2.308 \n",
      "Iteration 47/1000 - Loss: 2.305 \n",
      "Iteration 48/1000 - Loss: 2.301 \n",
      "Iteration 49/1000 - Loss: 2.298 \n",
      "Iteration 50/1000 - Loss: 2.294 \n",
      "Iteration 51/1000 - Loss: 2.291 \n",
      "Iteration 52/1000 - Loss: 2.287 \n",
      "Iteration 53/1000 - Loss: 2.283 \n",
      "Iteration 54/1000 - Loss: 2.279 \n",
      "Iteration 55/1000 - Loss: 2.274 \n",
      "Iteration 56/1000 - Loss: 2.270 \n",
      "Iteration 57/1000 - Loss: 2.266 \n",
      "Iteration 58/1000 - Loss: 2.261 \n",
      "Iteration 59/1000 - Loss: 2.257 \n",
      "Iteration 60/1000 - Loss: 2.252 \n",
      "Iteration 61/1000 - Loss: 2.247 \n",
      "Iteration 62/1000 - Loss: 2.242 \n",
      "Iteration 63/1000 - Loss: 2.237 \n",
      "Iteration 64/1000 - Loss: 2.232 \n",
      "Iteration 65/1000 - Loss: 2.227 \n",
      "Iteration 66/1000 - Loss: 2.222 \n",
      "Iteration 67/1000 - Loss: 2.217 \n",
      "Iteration 68/1000 - Loss: 2.211 \n",
      "Iteration 69/1000 - Loss: 2.206 \n",
      "Iteration 70/1000 - Loss: 2.200 \n",
      "Iteration 71/1000 - Loss: 2.195 \n",
      "Iteration 72/1000 - Loss: 2.189 \n",
      "Iteration 73/1000 - Loss: 2.183 \n",
      "Iteration 74/1000 - Loss: 2.177 \n",
      "Iteration 75/1000 - Loss: 2.171 \n",
      "Iteration 76/1000 - Loss: 2.166 \n",
      "Iteration 77/1000 - Loss: 2.160 \n",
      "Iteration 78/1000 - Loss: 2.153 \n",
      "Iteration 79/1000 - Loss: 2.147 \n",
      "Iteration 80/1000 - Loss: 2.141 \n",
      "Iteration 81/1000 - Loss: 2.135 \n",
      "Iteration 82/1000 - Loss: 2.129 \n",
      "Iteration 83/1000 - Loss: 2.123 \n",
      "Iteration 84/1000 - Loss: 2.116 \n",
      "Iteration 85/1000 - Loss: 2.110 \n",
      "Iteration 86/1000 - Loss: 2.104 \n",
      "Iteration 87/1000 - Loss: 2.098 \n",
      "Iteration 88/1000 - Loss: 2.091 \n",
      "Iteration 89/1000 - Loss: 2.085 \n",
      "Iteration 90/1000 - Loss: 2.079 \n",
      "Iteration 91/1000 - Loss: 2.073 \n",
      "Iteration 92/1000 - Loss: 2.067 \n",
      "Iteration 93/1000 - Loss: 2.061 \n",
      "Iteration 94/1000 - Loss: 2.055 \n",
      "Iteration 95/1000 - Loss: 2.049 \n",
      "Iteration 96/1000 - Loss: 2.044 \n",
      "Iteration 97/1000 - Loss: 2.038 \n",
      "Iteration 98/1000 - Loss: 2.032 \n",
      "Iteration 99/1000 - Loss: 2.027 \n",
      "Iteration 100/1000 - Loss: 2.021 \n",
      "Iteration 101/1000 - Loss: 2.016 \n",
      "Iteration 102/1000 - Loss: 2.011 \n",
      "Iteration 103/1000 - Loss: 2.006 \n",
      "Iteration 104/1000 - Loss: 2.001 \n",
      "Iteration 105/1000 - Loss: 1.996 \n",
      "Iteration 106/1000 - Loss: 1.991 \n",
      "Iteration 107/1000 - Loss: 1.986 \n",
      "Iteration 108/1000 - Loss: 1.982 \n",
      "Iteration 109/1000 - Loss: 1.977 \n",
      "Iteration 110/1000 - Loss: 1.973 \n",
      "Iteration 111/1000 - Loss: 1.968 \n",
      "Iteration 112/1000 - Loss: 1.964 \n",
      "Iteration 113/1000 - Loss: 1.960 \n",
      "Iteration 114/1000 - Loss: 1.956 \n",
      "Iteration 115/1000 - Loss: 1.952 \n",
      "Iteration 116/1000 - Loss: 1.948 \n",
      "Iteration 117/1000 - Loss: 1.944 \n",
      "Iteration 118/1000 - Loss: 1.940 \n",
      "Iteration 119/1000 - Loss: 1.936 \n",
      "Iteration 120/1000 - Loss: 1.932 \n",
      "Iteration 121/1000 - Loss: 1.928 \n",
      "Iteration 122/1000 - Loss: 1.925 \n",
      "Iteration 123/1000 - Loss: 1.921 \n",
      "Iteration 124/1000 - Loss: 1.917 \n",
      "Iteration 125/1000 - Loss: 1.913 \n",
      "Iteration 126/1000 - Loss: 1.910 \n",
      "Iteration 127/1000 - Loss: 1.906 \n",
      "Iteration 128/1000 - Loss: 1.902 \n",
      "Iteration 129/1000 - Loss: 1.899 \n",
      "Iteration 130/1000 - Loss: 1.895 \n",
      "Iteration 131/1000 - Loss: 1.892 \n",
      "Iteration 132/1000 - Loss: 1.888 \n",
      "Iteration 133/1000 - Loss: 1.884 \n",
      "Iteration 134/1000 - Loss: 1.880 \n",
      "Iteration 135/1000 - Loss: 1.877 \n",
      "Iteration 136/1000 - Loss: 1.873 \n",
      "Iteration 137/1000 - Loss: 1.869 \n",
      "Iteration 138/1000 - Loss: 1.865 \n",
      "Iteration 139/1000 - Loss: 1.862 \n",
      "Iteration 140/1000 - Loss: 1.858 \n",
      "Iteration 141/1000 - Loss: 1.854 \n",
      "Iteration 142/1000 - Loss: 1.850 \n",
      "Iteration 143/1000 - Loss: 1.846 \n",
      "Iteration 144/1000 - Loss: 1.842 \n",
      "Iteration 145/1000 - Loss: 1.838 \n",
      "Iteration 146/1000 - Loss: 1.834 \n",
      "Iteration 147/1000 - Loss: 1.830 \n",
      "Iteration 148/1000 - Loss: 1.826 \n",
      "Iteration 149/1000 - Loss: 1.821 \n",
      "Iteration 150/1000 - Loss: 1.817 \n",
      "Iteration 151/1000 - Loss: 1.813 \n",
      "Iteration 152/1000 - Loss: 1.808 \n",
      "Iteration 153/1000 - Loss: 1.804 \n",
      "Iteration 154/1000 - Loss: 1.799 \n",
      "Iteration 155/1000 - Loss: 1.795 \n",
      "Iteration 156/1000 - Loss: 1.790 \n",
      "Iteration 157/1000 - Loss: 1.785 \n",
      "Iteration 158/1000 - Loss: 1.780 \n",
      "Iteration 159/1000 - Loss: 1.775 \n",
      "Iteration 160/1000 - Loss: 1.770 \n",
      "Iteration 161/1000 - Loss: 1.765 \n",
      "Iteration 162/1000 - Loss: 1.760 \n",
      "Iteration 163/1000 - Loss: 1.755 \n",
      "Iteration 164/1000 - Loss: 1.749 \n",
      "Iteration 165/1000 - Loss: 1.744 \n",
      "Iteration 166/1000 - Loss: 1.739 \n",
      "Iteration 167/1000 - Loss: 1.733 \n",
      "Iteration 168/1000 - Loss: 1.727 \n",
      "Iteration 169/1000 - Loss: 1.721 \n",
      "Iteration 170/1000 - Loss: 1.715 \n",
      "Iteration 171/1000 - Loss: 1.709 \n",
      "Iteration 172/1000 - Loss: 1.703 \n",
      "Iteration 173/1000 - Loss: 1.697 \n",
      "Iteration 174/1000 - Loss: 1.691 \n",
      "Iteration 175/1000 - Loss: 1.684 \n",
      "Iteration 176/1000 - Loss: 1.678 \n",
      "Iteration 177/1000 - Loss: 1.671 \n",
      "Iteration 178/1000 - Loss: 1.664 \n",
      "Iteration 179/1000 - Loss: 1.657 \n",
      "Iteration 180/1000 - Loss: 1.650 \n",
      "Iteration 181/1000 - Loss: 1.643 \n",
      "Iteration 182/1000 - Loss: 1.636 \n",
      "Iteration 183/1000 - Loss: 1.628 \n",
      "Iteration 184/1000 - Loss: 1.621 \n",
      "Iteration 185/1000 - Loss: 1.613 \n",
      "Iteration 186/1000 - Loss: 1.605 \n",
      "Iteration 187/1000 - Loss: 1.597 \n",
      "Iteration 188/1000 - Loss: 1.589 \n",
      "Iteration 189/1000 - Loss: 1.581 \n",
      "Iteration 190/1000 - Loss: 1.573 \n",
      "Iteration 191/1000 - Loss: 1.564 \n",
      "Iteration 192/1000 - Loss: 1.556 \n",
      "Iteration 193/1000 - Loss: 1.547 \n",
      "Iteration 194/1000 - Loss: 1.538 \n",
      "Iteration 195/1000 - Loss: 1.529 \n",
      "Iteration 196/1000 - Loss: 1.520 \n",
      "Iteration 197/1000 - Loss: 1.510 \n",
      "Iteration 198/1000 - Loss: 1.501 \n",
      "Iteration 199/1000 - Loss: 1.491 \n",
      "Iteration 200/1000 - Loss: 1.482 \n",
      "Iteration 201/1000 - Loss: 1.472 \n",
      "Iteration 202/1000 - Loss: 1.462 \n",
      "Iteration 203/1000 - Loss: 1.452 \n",
      "Iteration 204/1000 - Loss: 1.441 \n",
      "Iteration 205/1000 - Loss: 1.431 \n",
      "Iteration 206/1000 - Loss: 1.420 \n",
      "Iteration 207/1000 - Loss: 1.410 \n",
      "Iteration 208/1000 - Loss: 1.399 \n",
      "Iteration 209/1000 - Loss: 1.388 \n",
      "Iteration 210/1000 - Loss: 1.377 \n",
      "Iteration 211/1000 - Loss: 1.365 \n",
      "Iteration 212/1000 - Loss: 1.354 \n",
      "Iteration 213/1000 - Loss: 1.342 \n",
      "Iteration 214/1000 - Loss: 1.331 \n",
      "Iteration 215/1000 - Loss: 1.319 \n",
      "Iteration 216/1000 - Loss: 1.307 \n",
      "Iteration 217/1000 - Loss: 1.295 \n",
      "Iteration 218/1000 - Loss: 1.283 \n",
      "Iteration 219/1000 - Loss: 1.271 \n",
      "Iteration 220/1000 - Loss: 1.259 \n",
      "Iteration 221/1000 - Loss: 1.246 \n",
      "Iteration 222/1000 - Loss: 1.234 \n",
      "Iteration 223/1000 - Loss: 1.221 \n",
      "Iteration 224/1000 - Loss: 1.209 \n",
      "Iteration 225/1000 - Loss: 1.196 \n",
      "Iteration 226/1000 - Loss: 1.183 \n",
      "Iteration 227/1000 - Loss: 1.170 \n",
      "Iteration 228/1000 - Loss: 1.158 \n",
      "Iteration 229/1000 - Loss: 1.145 \n",
      "Iteration 230/1000 - Loss: 1.132 \n",
      "Iteration 231/1000 - Loss: 1.118 \n",
      "Iteration 232/1000 - Loss: 1.105 \n",
      "Iteration 233/1000 - Loss: 1.092 \n",
      "Iteration 234/1000 - Loss: 1.079 \n",
      "Iteration 235/1000 - Loss: 1.065 \n",
      "Iteration 236/1000 - Loss: 1.052 \n",
      "Iteration 237/1000 - Loss: 1.038 \n",
      "Iteration 238/1000 - Loss: 1.025 \n",
      "Iteration 239/1000 - Loss: 1.011 \n",
      "Iteration 240/1000 - Loss: 0.998 \n",
      "Iteration 241/1000 - Loss: 0.984 \n",
      "Iteration 242/1000 - Loss: 0.970 \n",
      "Iteration 243/1000 - Loss: 0.957 \n",
      "Iteration 244/1000 - Loss: 0.943 \n",
      "Iteration 245/1000 - Loss: 0.929 \n",
      "Iteration 246/1000 - Loss: 0.915 \n",
      "Iteration 247/1000 - Loss: 0.901 \n",
      "Iteration 248/1000 - Loss: 0.887 \n",
      "Iteration 249/1000 - Loss: 0.873 \n",
      "Iteration 250/1000 - Loss: 0.859 \n",
      "Iteration 251/1000 - Loss: 0.845 \n",
      "Iteration 252/1000 - Loss: 0.831 \n",
      "Iteration 253/1000 - Loss: 0.817 \n",
      "Iteration 254/1000 - Loss: 0.803 \n",
      "Iteration 255/1000 - Loss: 0.789 \n",
      "Iteration 256/1000 - Loss: 0.775 \n",
      "Iteration 257/1000 - Loss: 0.761 \n",
      "Iteration 258/1000 - Loss: 0.747 \n",
      "Iteration 259/1000 - Loss: 0.733 \n",
      "Iteration 260/1000 - Loss: 0.719 \n",
      "Iteration 261/1000 - Loss: 0.704 \n",
      "Iteration 262/1000 - Loss: 0.690 \n",
      "Iteration 263/1000 - Loss: 0.676 \n",
      "Iteration 264/1000 - Loss: 0.662 \n",
      "Iteration 265/1000 - Loss: 0.648 \n",
      "Iteration 266/1000 - Loss: 0.634 \n",
      "Iteration 267/1000 - Loss: 0.620 \n",
      "Iteration 268/1000 - Loss: 0.606 \n",
      "Iteration 269/1000 - Loss: 0.592 \n",
      "Iteration 270/1000 - Loss: 0.577 \n",
      "Iteration 271/1000 - Loss: 0.563 \n",
      "Iteration 272/1000 - Loss: 0.549 \n",
      "Iteration 273/1000 - Loss: 0.536 \n",
      "Iteration 274/1000 - Loss: 0.522 \n",
      "Iteration 275/1000 - Loss: 0.519 \n",
      "Iteration 276/1000 - Loss: 0.658 \n",
      "Iteration 277/1000 - Loss: 0.559 \n",
      "Iteration 278/1000 - Loss: 0.560 \n",
      "Iteration 279/1000 - Loss: 0.493 \n",
      "Iteration 280/1000 - Loss: 0.542 \n",
      "Iteration 281/1000 - Loss: 0.440 \n",
      "Iteration 282/1000 - Loss: 0.522 \n",
      "Iteration 283/1000 - Loss: 0.412 \n",
      "Iteration 284/1000 - Loss: 0.486 \n",
      "Iteration 285/1000 - Loss: 0.400 \n",
      "Iteration 286/1000 - Loss: 0.438 \n",
      "Iteration 287/1000 - Loss: 0.392 \n",
      "Iteration 288/1000 - Loss: 0.393 \n",
      "Iteration 289/1000 - Loss: 0.378 \n",
      "Iteration 290/1000 - Loss: 0.357 \n",
      "Iteration 291/1000 - Loss: 0.357 \n",
      "Iteration 292/1000 - Loss: 0.330 \n",
      "Iteration 293/1000 - Loss: 0.332 \n",
      "Iteration 294/1000 - Loss: 0.309 \n",
      "Iteration 295/1000 - Loss: 0.302 \n",
      "Iteration 296/1000 - Loss: 0.292 \n",
      "Iteration 297/1000 - Loss: 0.270 \n",
      "Iteration 298/1000 - Loss: 0.279 \n",
      "Iteration 299/1000 - Loss: 0.240 \n",
      "Iteration 300/1000 - Loss: 0.258 \n",
      "Iteration 301/1000 - Loss: 0.226 \n",
      "Iteration 302/1000 - Loss: 0.220 \n",
      "Iteration 303/1000 - Loss: 0.224 \n",
      "Iteration 304/1000 - Loss: 0.191 \n",
      "Iteration 305/1000 - Loss: 0.191 \n",
      "Iteration 306/1000 - Loss: 0.193 \n",
      "Iteration 307/1000 - Loss: 0.165 \n",
      "Iteration 308/1000 - Loss: 0.152 \n",
      "Iteration 309/1000 - Loss: 0.160 \n",
      "Iteration 310/1000 - Loss: 0.158 \n",
      "Iteration 311/1000 - Loss: 0.137 \n",
      "Iteration 312/1000 - Loss: 0.116 \n",
      "Iteration 313/1000 - Loss: 0.107 \n",
      "Iteration 314/1000 - Loss: 0.109 \n",
      "Iteration 315/1000 - Loss: 0.124 \n",
      "Iteration 316/1000 - Loss: 0.156 \n",
      "Iteration 317/1000 - Loss: 0.193 \n",
      "Iteration 318/1000 - Loss: 0.169 \n",
      "Iteration 319/1000 - Loss: 0.081 \n",
      "Iteration 320/1000 - Loss: 0.061 \n",
      "Iteration 321/1000 - Loss: 0.119 \n",
      "Iteration 322/1000 - Loss: 0.130 \n",
      "Iteration 323/1000 - Loss: 0.059 \n",
      "Iteration 324/1000 - Loss: 0.033 \n",
      "Iteration 325/1000 - Loss: 0.080 \n",
      "Iteration 326/1000 - Loss: 0.090 \n",
      "Iteration 327/1000 - Loss: 0.034 \n",
      "Iteration 328/1000 - Loss: 0.010 \n",
      "Iteration 329/1000 - Loss: 0.045 \n",
      "Iteration 330/1000 - Loss: 0.058 \n",
      "Iteration 331/1000 - Loss: 0.019 \n",
      "Iteration 332/1000 - Loss: -0.011 \n",
      "Iteration 333/1000 - Loss: 0.005 \n",
      "Iteration 334/1000 - Loss: 0.029 \n",
      "Iteration 335/1000 - Loss: 0.017 \n",
      "Iteration 336/1000 - Loss: -0.017 \n",
      "Iteration 337/1000 - Loss: -0.031 \n",
      "Iteration 338/1000 - Loss: -0.018 \n",
      "Iteration 339/1000 - Loss: 0.001 \n",
      "Iteration 340/1000 - Loss: -0.001 \n",
      "Iteration 341/1000 - Loss: -0.022 \n",
      "Iteration 342/1000 - Loss: -0.046 \n",
      "Iteration 343/1000 - Loss: -0.052 \n",
      "Iteration 344/1000 - Loss: -0.044 \n",
      "Iteration 345/1000 - Loss: -0.030 \n",
      "Iteration 346/1000 - Loss: -0.020 \n",
      "Iteration 347/1000 - Loss: -0.021 \n",
      "Iteration 348/1000 - Loss: -0.035 \n",
      "Iteration 349/1000 - Loss: -0.057 \n",
      "Iteration 350/1000 - Loss: -0.071 \n",
      "Iteration 351/1000 - Loss: -0.074 \n",
      "Iteration 352/1000 - Loss: -0.068 \n",
      "Iteration 353/1000 - Loss: -0.057 \n",
      "Iteration 354/1000 - Loss: -0.046 \n",
      "Iteration 355/1000 - Loss: -0.036 \n",
      "Iteration 356/1000 - Loss: -0.034 \n",
      "Iteration 357/1000 - Loss: -0.045 \n",
      "Iteration 358/1000 - Loss: -0.066 \n",
      "Iteration 359/1000 - Loss: -0.085 \n",
      "Iteration 360/1000 - Loss: -0.094 \n",
      "Iteration 361/1000 - Loss: -0.090 \n",
      "Iteration 362/1000 - Loss: -0.078 \n",
      "Iteration 363/1000 - Loss: -0.068 \n",
      "Iteration 364/1000 - Loss: -0.060 \n",
      "Iteration 365/1000 - Loss: -0.062 \n",
      "Iteration 366/1000 - Loss: -0.074 \n",
      "Iteration 367/1000 - Loss: -0.091 \n",
      "Iteration 368/1000 - Loss: -0.104 \n",
      "Iteration 369/1000 - Loss: -0.107 \n",
      "Iteration 370/1000 - Loss: -0.102 \n",
      "Iteration 371/1000 - Loss: -0.092 \n",
      "Iteration 372/1000 - Loss: -0.085 \n",
      "Iteration 373/1000 - Loss: -0.084 \n",
      "Iteration 374/1000 - Loss: -0.088 \n",
      "Iteration 375/1000 - Loss: -0.098 \n",
      "Iteration 376/1000 - Loss: -0.109 \n",
      "Iteration 377/1000 - Loss: -0.116 \n",
      "Iteration 378/1000 - Loss: -0.117 \n",
      "Iteration 379/1000 - Loss: -0.114 \n",
      "Iteration 380/1000 - Loss: -0.109 \n",
      "Iteration 381/1000 - Loss: -0.103 \n",
      "Iteration 382/1000 - Loss: -0.100 \n",
      "Iteration 383/1000 - Loss: -0.101 \n",
      "Iteration 384/1000 - Loss: -0.104 \n",
      "Iteration 385/1000 - Loss: -0.109 \n",
      "Iteration 386/1000 - Loss: -0.115 \n",
      "Iteration 387/1000 - Loss: -0.121 \n",
      "Iteration 388/1000 - Loss: -0.124 \n",
      "Iteration 389/1000 - Loss: -0.127 \n",
      "Iteration 390/1000 - Loss: -0.127 \n",
      "Iteration 391/1000 - Loss: -0.126 \n",
      "Iteration 392/1000 - Loss: -0.124 \n",
      "Iteration 393/1000 - Loss: -0.121 \n",
      "Iteration 394/1000 - Loss: -0.118 \n",
      "Iteration 395/1000 - Loss: -0.114 \n",
      "Iteration 396/1000 - Loss: -0.109 \n",
      "Iteration 397/1000 - Loss: -0.101 \n",
      "Iteration 398/1000 - Loss: -0.096 \n",
      "Iteration 399/1000 - Loss: -0.093 \n",
      "Iteration 400/1000 - Loss: -0.093 \n",
      "Iteration 401/1000 - Loss: -0.104 \n",
      "Iteration 402/1000 - Loss: -0.118 \n",
      "Iteration 403/1000 - Loss: -0.130 \n",
      "Iteration 404/1000 - Loss: -0.136 \n",
      "Iteration 405/1000 - Loss: -0.134 \n",
      "Iteration 406/1000 - Loss: -0.127 \n",
      "Iteration 407/1000 - Loss: -0.120 \n",
      "Iteration 408/1000 - Loss: -0.118 \n",
      "Iteration 409/1000 - Loss: -0.120 \n",
      "Iteration 410/1000 - Loss: -0.127 \n",
      "Iteration 411/1000 - Loss: -0.134 \n",
      "Iteration 412/1000 - Loss: -0.139 \n",
      "Iteration 413/1000 - Loss: -0.139 \n",
      "Iteration 414/1000 - Loss: -0.137 \n",
      "Iteration 415/1000 - Loss: -0.133 \n",
      "Iteration 416/1000 - Loss: -0.132 \n",
      "Iteration 417/1000 - Loss: -0.132 \n",
      "Iteration 418/1000 - Loss: -0.133 \n",
      "Iteration 419/1000 - Loss: -0.137 \n",
      "Iteration 420/1000 - Loss: -0.140 \n",
      "Iteration 421/1000 - Loss: -0.142 \n",
      "Iteration 422/1000 - Loss: -0.143 \n",
      "Iteration 423/1000 - Loss: -0.143 \n",
      "Iteration 424/1000 - Loss: -0.142 \n",
      "Iteration 425/1000 - Loss: -0.141 \n",
      "Iteration 426/1000 - Loss: -0.139 \n",
      "Iteration 427/1000 - Loss: -0.139 \n",
      "Iteration 428/1000 - Loss: -0.138 \n",
      "Iteration 429/1000 - Loss: -0.138 \n",
      "Iteration 430/1000 - Loss: -0.140 \n",
      "Iteration 431/1000 - Loss: -0.141 \n",
      "Iteration 432/1000 - Loss: -0.142 \n",
      "Iteration 433/1000 - Loss: -0.144 \n",
      "Iteration 434/1000 - Loss: -0.144 \n",
      "Iteration 435/1000 - Loss: -0.145 \n",
      "Iteration 436/1000 - Loss: -0.147 \n",
      "Iteration 437/1000 - Loss: -0.146 \n",
      "Iteration 438/1000 - Loss: -0.146 \n",
      "Iteration 439/1000 - Loss: -0.147 \n",
      "Iteration 440/1000 - Loss: -0.148 \n",
      "Iteration 441/1000 - Loss: -0.148 \n",
      "Iteration 442/1000 - Loss: -0.148 \n",
      "Iteration 443/1000 - Loss: -0.150 \n",
      "Iteration 444/1000 - Loss: -0.149 \n",
      "Iteration 445/1000 - Loss: -0.149 \n",
      "Iteration 446/1000 - Loss: -0.149 \n",
      "Iteration 447/1000 - Loss: -0.149 \n",
      "Iteration 448/1000 - Loss: -0.149 \n",
      "Iteration 449/1000 - Loss: -0.149 \n",
      "Iteration 450/1000 - Loss: -0.148 \n",
      "Iteration 451/1000 - Loss: -0.145 \n",
      "Iteration 452/1000 - Loss: -0.141 \n",
      "Iteration 453/1000 - Loss: -0.131 \n",
      "Iteration 454/1000 - Loss: -0.113 \n",
      "Iteration 455/1000 - Loss: -0.082 \n",
      "Iteration 456/1000 - Loss: -0.043 \n",
      "Iteration 457/1000 - Loss: -0.012 \n",
      "Iteration 458/1000 - Loss: -0.028 \n",
      "Iteration 459/1000 - Loss: -0.096 \n",
      "Iteration 460/1000 - Loss: -0.149 \n",
      "Iteration 461/1000 - Loss: -0.134 \n",
      "Iteration 462/1000 - Loss: -0.086 \n",
      "Iteration 463/1000 - Loss: -0.086 \n",
      "Iteration 464/1000 - Loss: -0.131 \n",
      "Iteration 465/1000 - Loss: -0.152 \n",
      "Iteration 466/1000 - Loss: -0.126 \n",
      "Iteration 467/1000 - Loss: -0.107 \n",
      "Iteration 468/1000 - Loss: -0.129 \n",
      "Iteration 469/1000 - Loss: -0.153 \n",
      "Iteration 470/1000 - Loss: -0.143 \n",
      "Iteration 471/1000 - Loss: -0.124 \n",
      "Iteration 472/1000 - Loss: -0.134 \n",
      "Iteration 473/1000 - Loss: -0.153 \n",
      "Iteration 474/1000 - Loss: -0.148 \n",
      "Iteration 475/1000 - Loss: -0.135 \n",
      "Iteration 476/1000 - Loss: -0.140 \n",
      "Iteration 477/1000 - Loss: -0.153 \n",
      "Iteration 478/1000 - Loss: -0.152 \n",
      "Iteration 479/1000 - Loss: -0.143 \n",
      "Iteration 480/1000 - Loss: -0.144 \n",
      "Iteration 481/1000 - Loss: -0.153 \n",
      "Iteration 482/1000 - Loss: -0.154 \n",
      "Iteration 483/1000 - Loss: -0.148 \n",
      "Iteration 484/1000 - Loss: -0.149 \n",
      "Iteration 485/1000 - Loss: -0.154 \n",
      "Iteration 486/1000 - Loss: -0.156 \n",
      "Iteration 487/1000 - Loss: -0.152 \n",
      "Iteration 488/1000 - Loss: -0.151 \n",
      "Iteration 489/1000 - Loss: -0.154 \n",
      "Iteration 490/1000 - Loss: -0.156 \n",
      "Iteration 491/1000 - Loss: -0.154 \n",
      "Iteration 492/1000 - Loss: -0.153 \n",
      "Iteration 493/1000 - Loss: -0.155 \n",
      "Iteration 494/1000 - Loss: -0.157 \n",
      "Iteration 495/1000 - Loss: -0.157 \n",
      "Iteration 496/1000 - Loss: -0.155 \n",
      "Iteration 497/1000 - Loss: -0.155 \n",
      "Iteration 498/1000 - Loss: -0.157 \n",
      "Iteration 499/1000 - Loss: -0.157 \n",
      "Iteration 500/1000 - Loss: -0.156 \n",
      "Iteration 501/1000 - Loss: -0.157 \n",
      "Iteration 502/1000 - Loss: -0.157 \n",
      "Iteration 503/1000 - Loss: -0.158 \n",
      "Iteration 504/1000 - Loss: -0.158 \n",
      "Iteration 505/1000 - Loss: -0.157 \n",
      "Iteration 506/1000 - Loss: -0.157 \n",
      "Iteration 507/1000 - Loss: -0.158 \n",
      "Iteration 508/1000 - Loss: -0.158 \n",
      "Iteration 509/1000 - Loss: -0.158 \n",
      "Iteration 510/1000 - Loss: -0.158 \n",
      "Iteration 511/1000 - Loss: -0.158 \n",
      "Iteration 512/1000 - Loss: -0.159 \n",
      "Iteration 513/1000 - Loss: -0.159 \n",
      "Iteration 514/1000 - Loss: -0.158 \n",
      "Iteration 515/1000 - Loss: -0.158 \n",
      "Iteration 516/1000 - Loss: -0.158 \n",
      "Iteration 517/1000 - Loss: -0.159 \n",
      "Iteration 518/1000 - Loss: -0.159 \n",
      "Iteration 519/1000 - Loss: -0.159 \n",
      "Iteration 520/1000 - Loss: -0.158 \n",
      "Iteration 521/1000 - Loss: -0.160 \n",
      "Iteration 522/1000 - Loss: -0.160 \n",
      "Iteration 523/1000 - Loss: -0.160 \n",
      "Iteration 524/1000 - Loss: -0.160 \n",
      "Iteration 525/1000 - Loss: -0.160 \n",
      "Iteration 526/1000 - Loss: -0.159 \n",
      "Iteration 527/1000 - Loss: -0.160 \n",
      "Iteration 528/1000 - Loss: -0.160 \n",
      "Iteration 529/1000 - Loss: -0.160 \n",
      "Iteration 530/1000 - Loss: -0.160 \n",
      "Iteration 531/1000 - Loss: -0.160 \n",
      "Iteration 532/1000 - Loss: -0.161 \n",
      "Iteration 533/1000 - Loss: -0.160 \n",
      "Iteration 534/1000 - Loss: -0.160 \n",
      "Iteration 535/1000 - Loss: -0.161 \n",
      "Iteration 536/1000 - Loss: -0.161 \n",
      "Iteration 537/1000 - Loss: -0.161 \n",
      "Iteration 538/1000 - Loss: -0.161 \n",
      "Iteration 539/1000 - Loss: -0.161 \n",
      "Iteration 540/1000 - Loss: -0.161 \n",
      "Iteration 541/1000 - Loss: -0.161 \n",
      "Iteration 542/1000 - Loss: -0.161 \n",
      "Iteration 543/1000 - Loss: -0.161 \n",
      "Iteration 544/1000 - Loss: -0.161 \n",
      "Iteration 545/1000 - Loss: -0.161 \n",
      "Iteration 546/1000 - Loss: -0.162 \n",
      "Iteration 547/1000 - Loss: -0.162 \n",
      "Iteration 548/1000 - Loss: -0.161 \n",
      "Iteration 549/1000 - Loss: -0.161 \n",
      "Iteration 550/1000 - Loss: -0.162 \n",
      "Iteration 551/1000 - Loss: -0.162 \n",
      "Iteration 552/1000 - Loss: -0.162 \n",
      "Iteration 553/1000 - Loss: -0.162 \n",
      "Iteration 554/1000 - Loss: -0.162 \n",
      "Iteration 555/1000 - Loss: -0.162 \n",
      "Iteration 556/1000 - Loss: -0.162 \n",
      "Iteration 557/1000 - Loss: -0.162 \n",
      "Iteration 558/1000 - Loss: -0.162 \n",
      "Iteration 559/1000 - Loss: -0.162 \n",
      "Iteration 560/1000 - Loss: -0.162 \n",
      "Iteration 561/1000 - Loss: -0.162 \n",
      "Iteration 562/1000 - Loss: -0.163 \n",
      "Iteration 563/1000 - Loss: -0.163 \n",
      "Iteration 564/1000 - Loss: -0.163 \n",
      "Iteration 565/1000 - Loss: -0.163 \n",
      "Iteration 566/1000 - Loss: -0.162 \n",
      "Iteration 567/1000 - Loss: -0.163 \n",
      "Iteration 568/1000 - Loss: -0.163 \n",
      "Iteration 569/1000 - Loss: -0.163 \n",
      "Iteration 570/1000 - Loss: -0.163 \n",
      "Iteration 571/1000 - Loss: -0.162 \n",
      "Iteration 572/1000 - Loss: -0.163 \n",
      "Iteration 573/1000 - Loss: -0.162 \n",
      "Iteration 574/1000 - Loss: -0.163 \n",
      "Iteration 575/1000 - Loss: -0.163 \n",
      "Iteration 576/1000 - Loss: -0.162 \n",
      "Iteration 577/1000 - Loss: -0.163 \n",
      "Iteration 578/1000 - Loss: -0.163 \n",
      "Iteration 579/1000 - Loss: -0.163 \n",
      "Iteration 580/1000 - Loss: -0.163 \n",
      "Iteration 581/1000 - Loss: -0.164 \n",
      "Iteration 582/1000 - Loss: -0.163 \n",
      "Iteration 583/1000 - Loss: -0.164 \n",
      "Iteration 584/1000 - Loss: -0.164 \n",
      "Iteration 585/1000 - Loss: -0.163 \n",
      "Iteration 586/1000 - Loss: -0.163 \n",
      "Iteration 587/1000 - Loss: -0.164 \n",
      "Iteration 588/1000 - Loss: -0.163 \n",
      "Iteration 589/1000 - Loss: -0.163 \n",
      "Iteration 590/1000 - Loss: -0.164 \n",
      "Iteration 591/1000 - Loss: -0.164 \n",
      "Iteration 592/1000 - Loss: -0.164 \n",
      "Iteration 593/1000 - Loss: -0.164 \n",
      "Iteration 594/1000 - Loss: -0.163 \n",
      "Iteration 595/1000 - Loss: -0.163 \n",
      "Iteration 596/1000 - Loss: -0.164 \n",
      "Iteration 597/1000 - Loss: -0.164 \n",
      "Iteration 598/1000 - Loss: -0.164 \n",
      "Iteration 599/1000 - Loss: -0.164 \n",
      "Iteration 600/1000 - Loss: -0.164 \n",
      "Iteration 601/1000 - Loss: -0.164 \n",
      "Iteration 602/1000 - Loss: -0.164 \n",
      "Iteration 603/1000 - Loss: -0.163 \n",
      "Iteration 604/1000 - Loss: -0.164 \n",
      "Iteration 605/1000 - Loss: -0.164 \n",
      "Iteration 606/1000 - Loss: -0.164 \n",
      "Iteration 607/1000 - Loss: -0.164 \n",
      "Iteration 608/1000 - Loss: -0.163 \n",
      "Iteration 609/1000 - Loss: -0.162 \n",
      "Iteration 610/1000 - Loss: -0.160 \n",
      "Iteration 611/1000 - Loss: -0.155 \n",
      "Iteration 612/1000 - Loss: -0.148 \n",
      "Iteration 613/1000 - Loss: -0.133 \n",
      "Iteration 614/1000 - Loss: -0.106 \n",
      "Iteration 615/1000 - Loss: -0.067 \n",
      "Iteration 616/1000 - Loss: -0.023 \n",
      "Iteration 617/1000 - Loss: 0.000 \n",
      "Iteration 618/1000 - Loss: -0.035 \n",
      "Iteration 619/1000 - Loss: -0.117 \n",
      "Iteration 620/1000 - Loss: -0.164 \n",
      "Iteration 621/1000 - Loss: -0.136 \n",
      "Iteration 622/1000 - Loss: -0.087 \n",
      "Iteration 623/1000 - Loss: -0.095 \n",
      "Iteration 624/1000 - Loss: -0.146 \n",
      "Iteration 625/1000 - Loss: -0.164 \n",
      "Iteration 626/1000 - Loss: -0.133 \n",
      "Iteration 627/1000 - Loss: -0.114 \n",
      "Iteration 628/1000 - Loss: -0.139 \n",
      "Iteration 629/1000 - Loss: -0.164 \n",
      "Iteration 630/1000 - Loss: -0.152 \n",
      "Iteration 631/1000 - Loss: -0.134 \n",
      "Iteration 632/1000 - Loss: -0.143 \n",
      "Iteration 633/1000 - Loss: -0.163 \n",
      "Iteration 634/1000 - Loss: -0.160 \n",
      "Iteration 635/1000 - Loss: -0.147 \n",
      "Iteration 636/1000 - Loss: -0.149 \n",
      "Iteration 637/1000 - Loss: -0.163 \n",
      "Iteration 638/1000 - Loss: -0.164 \n",
      "Iteration 639/1000 - Loss: -0.155 \n",
      "Iteration 640/1000 - Loss: -0.154 \n",
      "Iteration 641/1000 - Loss: -0.163 \n",
      "Iteration 642/1000 - Loss: -0.165 \n",
      "Iteration 643/1000 - Loss: -0.160 \n",
      "Iteration 644/1000 - Loss: -0.157 \n",
      "Iteration 645/1000 - Loss: -0.163 \n",
      "Iteration 646/1000 - Loss: -0.166 \n",
      "Iteration 647/1000 - Loss: -0.162 \n",
      "Iteration 648/1000 - Loss: -0.160 \n",
      "Iteration 649/1000 - Loss: -0.163 \n",
      "Iteration 650/1000 - Loss: -0.166 \n",
      "Iteration 651/1000 - Loss: -0.164 \n",
      "Iteration 652/1000 - Loss: -0.162 \n",
      "Iteration 653/1000 - Loss: -0.163 \n",
      "Iteration 654/1000 - Loss: -0.165 \n",
      "Iteration 655/1000 - Loss: -0.165 \n",
      "Iteration 656/1000 - Loss: -0.164 \n",
      "Iteration 657/1000 - Loss: -0.163 \n",
      "Iteration 658/1000 - Loss: -0.165 \n",
      "Iteration 659/1000 - Loss: -0.166 \n",
      "Iteration 660/1000 - Loss: -0.165 \n",
      "Iteration 661/1000 - Loss: -0.164 \n",
      "Iteration 662/1000 - Loss: -0.165 \n",
      "Iteration 663/1000 - Loss: -0.166 \n",
      "Iteration 664/1000 - Loss: -0.165 \n",
      "Iteration 665/1000 - Loss: -0.164 \n",
      "Iteration 666/1000 - Loss: -0.165 \n",
      "Iteration 667/1000 - Loss: -0.165 \n",
      "Iteration 668/1000 - Loss: -0.166 \n",
      "Iteration 669/1000 - Loss: -0.165 \n",
      "Iteration 670/1000 - Loss: -0.165 \n",
      "Iteration 671/1000 - Loss: -0.166 \n",
      "Iteration 672/1000 - Loss: -0.167 \n",
      "Iteration 673/1000 - Loss: -0.167 \n",
      "Iteration 674/1000 - Loss: -0.166 \n",
      "Iteration 675/1000 - Loss: -0.166 \n",
      "Iteration 676/1000 - Loss: -0.167 \n",
      "Iteration 677/1000 - Loss: -0.167 \n",
      "Iteration 678/1000 - Loss: -0.166 \n",
      "Iteration 679/1000 - Loss: -0.166 \n",
      "Iteration 680/1000 - Loss: -0.167 \n",
      "Iteration 681/1000 - Loss: -0.166 \n",
      "Iteration 682/1000 - Loss: -0.166 \n",
      "Iteration 683/1000 - Loss: -0.166 \n",
      "Iteration 684/1000 - Loss: -0.167 \n",
      "Iteration 685/1000 - Loss: -0.166 \n",
      "Iteration 686/1000 - Loss: -0.167 \n",
      "Iteration 687/1000 - Loss: -0.166 \n",
      "Iteration 688/1000 - Loss: -0.167 \n",
      "Iteration 689/1000 - Loss: -0.166 \n",
      "Iteration 690/1000 - Loss: -0.167 \n",
      "Iteration 691/1000 - Loss: -0.167 \n",
      "Iteration 692/1000 - Loss: -0.167 \n",
      "Iteration 693/1000 - Loss: -0.167 \n",
      "Iteration 694/1000 - Loss: -0.166 \n",
      "Iteration 695/1000 - Loss: -0.167 \n",
      "Iteration 696/1000 - Loss: -0.167 \n",
      "Iteration 697/1000 - Loss: -0.166 \n",
      "Iteration 698/1000 - Loss: -0.167 \n",
      "Iteration 699/1000 - Loss: -0.167 \n",
      "Iteration 700/1000 - Loss: -0.166 \n",
      "Iteration 701/1000 - Loss: -0.167 \n",
      "Iteration 702/1000 - Loss: -0.167 \n",
      "Iteration 703/1000 - Loss: -0.167 \n",
      "Iteration 704/1000 - Loss: -0.166 \n",
      "Iteration 705/1000 - Loss: -0.167 \n",
      "Iteration 706/1000 - Loss: -0.167 \n",
      "Iteration 707/1000 - Loss: -0.167 \n",
      "Iteration 708/1000 - Loss: -0.167 \n",
      "Iteration 709/1000 - Loss: -0.166 \n",
      "Iteration 710/1000 - Loss: -0.167 \n",
      "Iteration 711/1000 - Loss: -0.167 \n",
      "Iteration 712/1000 - Loss: -0.167 \n",
      "Iteration 713/1000 - Loss: -0.167 \n",
      "Iteration 714/1000 - Loss: -0.167 \n",
      "Iteration 715/1000 - Loss: -0.166 \n",
      "Iteration 716/1000 - Loss: -0.168 \n",
      "Iteration 717/1000 - Loss: -0.168 \n",
      "Iteration 718/1000 - Loss: -0.168 \n",
      "Iteration 719/1000 - Loss: -0.168 \n",
      "Iteration 720/1000 - Loss: -0.167 \n",
      "Iteration 721/1000 - Loss: -0.168 \n",
      "Iteration 722/1000 - Loss: -0.168 \n",
      "Iteration 723/1000 - Loss: -0.168 \n",
      "Iteration 724/1000 - Loss: -0.168 \n",
      "Iteration 725/1000 - Loss: -0.168 \n",
      "Iteration 726/1000 - Loss: -0.167 \n",
      "Iteration 727/1000 - Loss: -0.168 \n",
      "Iteration 728/1000 - Loss: -0.168 \n",
      "Iteration 729/1000 - Loss: -0.167 \n",
      "Iteration 730/1000 - Loss: -0.168 \n",
      "Iteration 731/1000 - Loss: -0.167 \n",
      "Iteration 732/1000 - Loss: -0.168 \n",
      "Iteration 733/1000 - Loss: -0.168 \n",
      "Iteration 734/1000 - Loss: -0.168 \n",
      "Iteration 735/1000 - Loss: -0.167 \n",
      "Iteration 736/1000 - Loss: -0.167 \n",
      "Iteration 737/1000 - Loss: -0.168 \n",
      "Iteration 738/1000 - Loss: -0.168 \n",
      "Iteration 739/1000 - Loss: -0.168 \n",
      "Iteration 740/1000 - Loss: -0.168 \n",
      "Iteration 741/1000 - Loss: -0.168 \n",
      "Iteration 742/1000 - Loss: -0.168 \n",
      "Iteration 743/1000 - Loss: -0.168 \n",
      "Iteration 744/1000 - Loss: -0.168 \n",
      "Iteration 745/1000 - Loss: -0.168 \n",
      "Iteration 746/1000 - Loss: -0.168 \n",
      "Iteration 747/1000 - Loss: -0.168 \n",
      "Iteration 748/1000 - Loss: -0.168 \n",
      "Iteration 749/1000 - Loss: -0.168 \n",
      "Iteration 750/1000 - Loss: -0.168 \n",
      "Iteration 751/1000 - Loss: -0.168 \n",
      "Iteration 752/1000 - Loss: -0.168 \n",
      "Iteration 753/1000 - Loss: -0.168 \n",
      "Iteration 754/1000 - Loss: -0.167 \n",
      "Iteration 755/1000 - Loss: -0.168 \n",
      "Iteration 756/1000 - Loss: -0.168 \n",
      "Iteration 757/1000 - Loss: -0.168 \n",
      "Iteration 758/1000 - Loss: -0.168 \n",
      "Iteration 759/1000 - Loss: -0.167 \n",
      "Iteration 760/1000 - Loss: -0.167 \n",
      "Iteration 761/1000 - Loss: -0.168 \n",
      "Iteration 762/1000 - Loss: -0.167 \n",
      "Iteration 763/1000 - Loss: -0.168 \n",
      "Iteration 764/1000 - Loss: -0.168 \n",
      "Iteration 765/1000 - Loss: -0.168 \n",
      "Iteration 766/1000 - Loss: -0.168 \n",
      "Iteration 767/1000 - Loss: -0.168 \n",
      "Iteration 768/1000 - Loss: -0.167 \n",
      "Iteration 769/1000 - Loss: -0.167 \n",
      "Iteration 770/1000 - Loss: -0.167 \n",
      "Iteration 771/1000 - Loss: -0.167 \n",
      "Iteration 772/1000 - Loss: -0.167 \n",
      "Iteration 773/1000 - Loss: -0.167 \n",
      "Iteration 774/1000 - Loss: -0.167 \n",
      "Iteration 775/1000 - Loss: -0.168 \n",
      "Iteration 776/1000 - Loss: -0.168 \n",
      "Iteration 777/1000 - Loss: -0.168 \n",
      "Iteration 778/1000 - Loss: -0.168 \n",
      "Iteration 779/1000 - Loss: -0.168 \n",
      "Iteration 780/1000 - Loss: -0.168 \n",
      "Iteration 781/1000 - Loss: -0.169 \n",
      "Iteration 782/1000 - Loss: -0.168 \n",
      "Iteration 783/1000 - Loss: -0.168 \n",
      "Iteration 784/1000 - Loss: -0.168 \n",
      "Iteration 785/1000 - Loss: -0.169 \n",
      "Iteration 786/1000 - Loss: -0.168 \n",
      "Iteration 787/1000 - Loss: -0.168 \n",
      "Iteration 788/1000 - Loss: -0.169 \n",
      "Iteration 789/1000 - Loss: -0.169 \n",
      "Iteration 790/1000 - Loss: -0.169 \n",
      "Iteration 791/1000 - Loss: -0.169 \n",
      "Iteration 792/1000 - Loss: -0.169 \n",
      "Iteration 793/1000 - Loss: -0.169 \n",
      "Iteration 794/1000 - Loss: -0.169 \n",
      "Iteration 795/1000 - Loss: -0.169 \n",
      "Iteration 796/1000 - Loss: -0.169 \n",
      "Iteration 797/1000 - Loss: -0.169 \n",
      "Iteration 798/1000 - Loss: -0.168 \n",
      "Iteration 799/1000 - Loss: -0.169 \n",
      "Iteration 800/1000 - Loss: -0.169 \n",
      "Iteration 801/1000 - Loss: -0.168 \n",
      "Iteration 802/1000 - Loss: -0.169 \n",
      "Iteration 803/1000 - Loss: -0.169 \n",
      "Iteration 804/1000 - Loss: -0.169 \n",
      "Iteration 805/1000 - Loss: -0.169 \n",
      "Iteration 806/1000 - Loss: -0.169 \n",
      "Iteration 807/1000 - Loss: -0.168 \n",
      "Iteration 808/1000 - Loss: -0.168 \n",
      "Iteration 809/1000 - Loss: -0.168 \n",
      "Iteration 810/1000 - Loss: -0.168 \n",
      "Iteration 811/1000 - Loss: -0.168 \n",
      "Iteration 812/1000 - Loss: -0.168 \n",
      "Iteration 813/1000 - Loss: -0.168 \n",
      "Iteration 814/1000 - Loss: -0.167 \n",
      "Iteration 815/1000 - Loss: -0.166 \n",
      "Iteration 816/1000 - Loss: -0.165 \n",
      "Iteration 817/1000 - Loss: -0.161 \n",
      "Iteration 818/1000 - Loss: -0.154 \n",
      "Iteration 819/1000 - Loss: -0.143 \n",
      "Iteration 820/1000 - Loss: -0.123 \n",
      "Iteration 821/1000 - Loss: -0.092 \n",
      "Iteration 822/1000 - Loss: -0.052 \n",
      "Iteration 823/1000 - Loss: -0.015 \n",
      "Iteration 824/1000 - Loss: -0.013 \n",
      "Iteration 825/1000 - Loss: -0.069 \n",
      "Iteration 826/1000 - Loss: -0.142 \n",
      "Iteration 827/1000 - Loss: -0.168 \n",
      "Iteration 828/1000 - Loss: -0.136 \n",
      "Iteration 829/1000 - Loss: -0.094 \n",
      "Iteration 830/1000 - Loss: -0.098 \n",
      "Iteration 831/1000 - Loss: -0.141 \n",
      "Iteration 832/1000 - Loss: -0.169 \n",
      "Iteration 833/1000 - Loss: -0.152 \n",
      "Iteration 834/1000 - Loss: -0.126 \n",
      "Iteration 835/1000 - Loss: -0.130 \n",
      "Iteration 836/1000 - Loss: -0.158 \n",
      "Iteration 837/1000 - Loss: -0.168 \n",
      "Iteration 838/1000 - Loss: -0.153 \n",
      "Iteration 839/1000 - Loss: -0.141 \n",
      "Iteration 840/1000 - Loss: -0.152 \n",
      "Iteration 841/1000 - Loss: -0.168 \n",
      "Iteration 842/1000 - Loss: -0.166 \n",
      "Iteration 843/1000 - Loss: -0.154 \n",
      "Iteration 844/1000 - Loss: -0.154 \n",
      "Iteration 845/1000 - Loss: -0.164 \n",
      "Iteration 846/1000 - Loss: -0.169 \n",
      "Iteration 847/1000 - Loss: -0.163 \n",
      "Iteration 848/1000 - Loss: -0.159 \n",
      "Iteration 849/1000 - Loss: -0.162 \n",
      "Iteration 850/1000 - Loss: -0.168 \n",
      "Iteration 851/1000 - Loss: -0.168 \n",
      "Iteration 852/1000 - Loss: -0.163 \n",
      "Iteration 853/1000 - Loss: -0.163 \n",
      "Iteration 854/1000 - Loss: -0.167 \n",
      "Iteration 855/1000 - Loss: -0.169 \n",
      "Iteration 856/1000 - Loss: -0.167 \n",
      "Iteration 857/1000 - Loss: -0.165 \n",
      "Iteration 858/1000 - Loss: -0.166 \n",
      "Iteration 859/1000 - Loss: -0.168 \n",
      "Iteration 860/1000 - Loss: -0.168 \n",
      "Iteration 861/1000 - Loss: -0.167 \n",
      "Iteration 862/1000 - Loss: -0.166 \n",
      "Iteration 863/1000 - Loss: -0.168 \n",
      "Iteration 864/1000 - Loss: -0.168 \n",
      "Iteration 865/1000 - Loss: -0.168 \n",
      "Iteration 866/1000 - Loss: -0.169 \n",
      "Iteration 867/1000 - Loss: -0.168 \n",
      "Iteration 868/1000 - Loss: -0.170 \n",
      "Iteration 869/1000 - Loss: -0.170 \n",
      "Iteration 870/1000 - Loss: -0.169 \n",
      "Iteration 871/1000 - Loss: -0.169 \n",
      "Iteration 872/1000 - Loss: -0.169 \n",
      "Iteration 873/1000 - Loss: -0.169 \n",
      "Iteration 874/1000 - Loss: -0.170 \n",
      "Iteration 875/1000 - Loss: -0.169 \n",
      "Iteration 876/1000 - Loss: -0.169 \n",
      "Iteration 877/1000 - Loss: -0.169 \n",
      "Iteration 878/1000 - Loss: -0.169 \n",
      "Iteration 879/1000 - Loss: -0.170 \n",
      "Iteration 880/1000 - Loss: -0.170 \n",
      "Iteration 881/1000 - Loss: -0.170 \n",
      "Iteration 882/1000 - Loss: -0.170 \n",
      "Iteration 883/1000 - Loss: -0.170 \n",
      "Iteration 884/1000 - Loss: -0.170 \n",
      "Iteration 885/1000 - Loss: -0.169 \n",
      "Iteration 886/1000 - Loss: -0.170 \n",
      "Iteration 887/1000 - Loss: -0.170 \n",
      "Iteration 888/1000 - Loss: -0.169 \n",
      "Iteration 889/1000 - Loss: -0.170 \n",
      "Iteration 890/1000 - Loss: -0.169 \n",
      "Iteration 891/1000 - Loss: -0.170 \n",
      "Iteration 892/1000 - Loss: -0.170 \n",
      "Iteration 893/1000 - Loss: -0.170 \n",
      "Iteration 894/1000 - Loss: -0.170 \n",
      "Iteration 895/1000 - Loss: -0.169 \n",
      "Iteration 896/1000 - Loss: -0.169 \n",
      "Iteration 897/1000 - Loss: -0.169 \n",
      "Iteration 898/1000 - Loss: -0.169 \n",
      "Iteration 899/1000 - Loss: -0.170 \n",
      "Iteration 900/1000 - Loss: -0.169 \n",
      "Iteration 901/1000 - Loss: -0.170 \n",
      "Iteration 902/1000 - Loss: -0.170 \n",
      "Iteration 903/1000 - Loss: -0.170 \n",
      "Iteration 904/1000 - Loss: -0.170 \n",
      "Iteration 905/1000 - Loss: -0.170 \n",
      "Iteration 906/1000 - Loss: -0.169 \n",
      "Iteration 907/1000 - Loss: -0.170 \n",
      "Iteration 908/1000 - Loss: -0.170 \n",
      "Iteration 909/1000 - Loss: -0.170 \n",
      "Iteration 910/1000 - Loss: -0.170 \n",
      "Iteration 911/1000 - Loss: -0.169 \n",
      "Iteration 912/1000 - Loss: -0.170 \n",
      "Iteration 913/1000 - Loss: -0.169 \n",
      "Iteration 914/1000 - Loss: -0.170 \n",
      "Iteration 915/1000 - Loss: -0.170 \n",
      "Iteration 916/1000 - Loss: -0.170 \n",
      "Iteration 917/1000 - Loss: -0.170 \n",
      "Iteration 918/1000 - Loss: -0.170 \n",
      "Iteration 919/1000 - Loss: -0.170 \n",
      "Iteration 920/1000 - Loss: -0.169 \n",
      "Iteration 921/1000 - Loss: -0.170 \n",
      "Iteration 922/1000 - Loss: -0.170 \n",
      "Iteration 923/1000 - Loss: -0.170 \n",
      "Iteration 924/1000 - Loss: -0.169 \n",
      "Iteration 925/1000 - Loss: -0.170 \n",
      "Iteration 926/1000 - Loss: -0.170 \n",
      "Iteration 927/1000 - Loss: -0.170 \n",
      "Iteration 928/1000 - Loss: -0.170 \n",
      "Iteration 929/1000 - Loss: -0.170 \n",
      "Iteration 930/1000 - Loss: -0.170 \n",
      "Iteration 931/1000 - Loss: -0.169 \n",
      "Iteration 932/1000 - Loss: -0.170 \n",
      "Iteration 933/1000 - Loss: -0.169 \n",
      "Iteration 934/1000 - Loss: -0.169 \n",
      "Iteration 935/1000 - Loss: -0.170 \n",
      "Iteration 936/1000 - Loss: -0.170 \n",
      "Iteration 937/1000 - Loss: -0.169 \n",
      "Iteration 938/1000 - Loss: -0.170 \n",
      "Iteration 939/1000 - Loss: -0.169 \n",
      "Iteration 940/1000 - Loss: -0.169 \n",
      "Iteration 941/1000 - Loss: -0.170 \n",
      "Iteration 942/1000 - Loss: -0.170 \n",
      "Iteration 943/1000 - Loss: -0.169 \n",
      "Iteration 944/1000 - Loss: -0.169 \n",
      "Iteration 945/1000 - Loss: -0.170 \n",
      "Iteration 946/1000 - Loss: -0.170 \n",
      "Iteration 947/1000 - Loss: -0.170 \n",
      "Iteration 948/1000 - Loss: -0.170 \n",
      "Iteration 949/1000 - Loss: -0.170 \n",
      "Iteration 950/1000 - Loss: -0.170 \n",
      "Iteration 951/1000 - Loss: -0.170 \n",
      "Iteration 952/1000 - Loss: -0.170 \n",
      "Iteration 953/1000 - Loss: -0.170 \n",
      "Iteration 954/1000 - Loss: -0.170 \n",
      "Iteration 955/1000 - Loss: -0.170 \n",
      "Iteration 956/1000 - Loss: -0.170 \n",
      "Iteration 957/1000 - Loss: -0.170 \n",
      "Iteration 958/1000 - Loss: -0.170 \n",
      "Iteration 959/1000 - Loss: -0.170 \n",
      "Iteration 960/1000 - Loss: -0.170 \n",
      "Iteration 961/1000 - Loss: -0.170 \n",
      "Iteration 962/1000 - Loss: -0.170 \n",
      "Iteration 963/1000 - Loss: -0.170 \n",
      "Iteration 964/1000 - Loss: -0.170 \n",
      "Iteration 965/1000 - Loss: -0.170 \n",
      "Iteration 966/1000 - Loss: -0.170 \n",
      "Iteration 967/1000 - Loss: -0.170 \n",
      "Iteration 968/1000 - Loss: -0.170 \n",
      "Iteration 969/1000 - Loss: -0.170 \n",
      "Iteration 970/1000 - Loss: -0.169 \n",
      "Iteration 971/1000 - Loss: -0.170 \n",
      "Iteration 972/1000 - Loss: -0.170 \n",
      "Iteration 973/1000 - Loss: -0.169 \n",
      "Iteration 974/1000 - Loss: -0.170 \n",
      "Iteration 975/1000 - Loss: -0.170 \n",
      "Iteration 976/1000 - Loss: -0.170 \n",
      "Iteration 977/1000 - Loss: -0.169 \n",
      "Iteration 978/1000 - Loss: -0.170 \n",
      "Iteration 979/1000 - Loss: -0.169 \n",
      "Iteration 980/1000 - Loss: -0.170 \n",
      "Iteration 981/1000 - Loss: -0.170 \n",
      "Iteration 982/1000 - Loss: -0.170 \n",
      "Iteration 983/1000 - Loss: -0.170 \n",
      "Iteration 984/1000 - Loss: -0.169 \n",
      "Iteration 985/1000 - Loss: -0.170 \n",
      "Iteration 986/1000 - Loss: -0.170 \n",
      "Iteration 987/1000 - Loss: -0.169 \n",
      "Iteration 988/1000 - Loss: -0.170 \n",
      "Iteration 989/1000 - Loss: -0.170 \n",
      "Iteration 990/1000 - Loss: -0.170 \n",
      "Iteration 991/1000 - Loss: -0.170 \n",
      "Iteration 992/1000 - Loss: -0.169 \n",
      "Iteration 993/1000 - Loss: -0.170 \n",
      "Iteration 994/1000 - Loss: -0.170 \n",
      "Iteration 995/1000 - Loss: -0.170 \n",
      "Iteration 996/1000 - Loss: -0.170 \n",
      "Iteration 997/1000 - Loss: -0.170 \n",
      "Iteration 998/1000 - Loss: -0.170 \n",
      "Iteration 999/1000 - Loss: -0.171 \n",
      "Iteration 1000/1000 - Loss: -0.171 \n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "hogde_gp.train(model, likelihood, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 5.07415461470373e-05\n",
      "Test MSE: 4.291597299754812e-09\n",
      "Test R2: 1.0\n",
      "Test MLSS: -3.288797616958618\n",
      "Test NLPD: -3.5441062450408936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([168]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "hogde_gp.predict(model, likelihood, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
